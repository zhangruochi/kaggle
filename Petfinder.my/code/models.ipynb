{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'test', 'train_metadata', 'test_sentiment', 'train_sentiment', 'train', 'train_images']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "working_dir = \"../input\"\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import ttest_ind_from_stats\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.preprocessing import  OneHotEncoder\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import xgboost as xgb\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import os\n",
    "from collections import Counter\n",
    "from functools import cmp_to_key\n",
    "import json\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Dropout\n",
    "import pickle as pkl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "41acccdb090b65a330fee0f195d5966aca363b9c"
   },
   "source": [
    "> ## csv model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "7be76cdbec44cdeed20389269ab032f47056a6b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>...</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Fee</th>\n",
       "      <th>State</th>\n",
       "      <th>RescuerID</th>\n",
       "      <th>VideoAmt</th>\n",
       "      <th>Description</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PetID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86e1089a3</th>\n",
       "      <td>2</td>\n",
       "      <td>Nibble</td>\n",
       "      <td>3</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>41326</td>\n",
       "      <td>8480853f516546f6cf33aa88cd76c379</td>\n",
       "      <td>0</td>\n",
       "      <td>Nibble is a 3+ month old ball of cuteness. He ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6296e909a</th>\n",
       "      <td>2</td>\n",
       "      <td>No Name Yet</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41401</td>\n",
       "      <td>3082c7125d8fb66f7dd4bff4192c8b14</td>\n",
       "      <td>0</td>\n",
       "      <td>I just found it alone yesterday near my apartm...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422e4906</th>\n",
       "      <td>1</td>\n",
       "      <td>Brisco</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>fa90fa5b1ee11c86938398b60abc32cb</td>\n",
       "      <td>0</td>\n",
       "      <td>Their pregnant mother was dumped by her irresp...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5842f1ff5</th>\n",
       "      <td>1</td>\n",
       "      <td>Miko</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>41401</td>\n",
       "      <td>9238e4f44c71a75282e62f7136c6b240</td>\n",
       "      <td>0</td>\n",
       "      <td>Good guard dog, very alert, active, obedience ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850a43f90</th>\n",
       "      <td>1</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>95481e953f8aed9ec3d16fc4509537e8</td>\n",
       "      <td>0</td>\n",
       "      <td>This handsome yet cute boy is up for adoption....</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Type         Name  Age  Breed1  Breed2  Gender  Color1  Color2  \\\n",
       "PetID                                                                       \n",
       "86e1089a3     2       Nibble    3     299       0       1       1       7   \n",
       "6296e909a     2  No Name Yet    1     265       0       1       1       2   \n",
       "3422e4906     1       Brisco    1     307       0       1       2       7   \n",
       "5842f1ff5     1         Miko    4     307       0       2       1       2   \n",
       "850a43f90     1       Hunter    1     307       0       1       1       0   \n",
       "\n",
       "           Color3  MaturitySize  ...  Sterilized  Health  Quantity  Fee  \\\n",
       "PetID                            ...                                      \n",
       "86e1089a3       0             1  ...           2       1         1  100   \n",
       "6296e909a       0             2  ...           3       1         1    0   \n",
       "3422e4906       0             2  ...           2       1         1    0   \n",
       "5842f1ff5       0             2  ...           2       1         1  150   \n",
       "850a43f90       0             2  ...           2       1         1    0   \n",
       "\n",
       "           State                         RescuerID  VideoAmt  \\\n",
       "PetID                                                          \n",
       "86e1089a3  41326  8480853f516546f6cf33aa88cd76c379         0   \n",
       "6296e909a  41401  3082c7125d8fb66f7dd4bff4192c8b14         0   \n",
       "3422e4906  41326  fa90fa5b1ee11c86938398b60abc32cb         0   \n",
       "5842f1ff5  41401  9238e4f44c71a75282e62f7136c6b240         0   \n",
       "850a43f90  41326  95481e953f8aed9ec3d16fc4509537e8         0   \n",
       "\n",
       "                                                 Description PhotoAmt  \\\n",
       "PetID                                                                   \n",
       "86e1089a3  Nibble is a 3+ month old ball of cuteness. He ...      1.0   \n",
       "6296e909a  I just found it alone yesterday near my apartm...      2.0   \n",
       "3422e4906  Their pregnant mother was dumped by her irresp...      7.0   \n",
       "5842f1ff5  Good guard dog, very alert, active, obedience ...      8.0   \n",
       "850a43f90  This handsome yet cute boy is up for adoption....      3.0   \n",
       "\n",
       "           AdoptionSpeed  \n",
       "PetID                     \n",
       "86e1089a3              2  \n",
       "6296e909a              0  \n",
       "3422e4906              3  \n",
       "5842f1ff5              2  \n",
       "850a43f90              2  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_csv(path):\n",
    "    csv_dataset = pd.read_csv(path,index_col=\"PetID\")\n",
    "    return csv_dataset\n",
    "csv_dataset = load_csv(working_dir+\"/train/\"+\"train.csv\")\n",
    "print(csv_dataset.shape)\n",
    "csv_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we can see \"Name\" \"Description\" has NaN Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type             14993\n",
       "Name             13736\n",
       "Age              14993\n",
       "Breed1           14993\n",
       "Breed2           14993\n",
       "Gender           14993\n",
       "Color1           14993\n",
       "Color2           14993\n",
       "Color3           14993\n",
       "MaturitySize     14993\n",
       "FurLength        14993\n",
       "Vaccinated       14993\n",
       "Dewormed         14993\n",
       "Sterilized       14993\n",
       "Health           14993\n",
       "Quantity         14993\n",
       "Fee              14993\n",
       "State            14993\n",
       "RescuerID        14993\n",
       "VideoAmt         14993\n",
       "Description      14981\n",
       "PhotoAmt         14993\n",
       "AdoptionSpeed    14993\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9061,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(nan, 1257),\n",
       " ('Baby', 66),\n",
       " ('Lucky', 64),\n",
       " ('Brownie', 54),\n",
       " ('No Name', 54),\n",
       " ('Mimi', 52),\n",
       " ('Blackie', 49),\n",
       " ('Puppy', 45),\n",
       " ('Kitty', 39),\n",
       " ('Max', 39),\n",
       " ('Kittens', 39),\n",
       " ('Oreo', 36),\n",
       " ('Coco', 35),\n",
       " ('Tiger', 34),\n",
       " ('Angel', 33),\n",
       " ('Milo', 32),\n",
       " ('Bobby', 30),\n",
       " ('Snowy', 30),\n",
       " ('Lucy', 29),\n",
       " ('Kiki', 29),\n",
       " ('Lily', 28),\n",
       " ('Tom', 27),\n",
       " ('Ginger', 26),\n",
       " ('Puppies', 26),\n",
       " ('Prince', 25),\n",
       " ('Happy', 25),\n",
       " ('Daisy', 24),\n",
       " ('Kitten', 23),\n",
       " ('Simba', 23),\n",
       " ('Lola', 23),\n",
       " ('Bella', 23),\n",
       " ('Rocky', 23),\n",
       " ('No Name Yet', 22),\n",
       " ('Molly', 22),\n",
       " ('Momo', 22),\n",
       " ('Princess', 22),\n",
       " ('Luna', 22),\n",
       " ('Buddy', 21),\n",
       " ('Tommy', 21),\n",
       " ('Fluffy', 21),\n",
       " ('Panda', 21),\n",
       " ('Peanut', 20),\n",
       " ('Cookie', 20),\n",
       " ('Snow', 20),\n",
       " ('Bobo', 20),\n",
       " ('Toby', 19),\n",
       " ('Mickey', 18),\n",
       " ('Shadow', 18),\n",
       " ('Blacky', 18),\n",
       " ('Teddy', 17),\n",
       " ('Lulu', 17),\n",
       " ('Coffee', 17),\n",
       " ('Oyen', 17),\n",
       " ('Leo', 17),\n",
       " ('Minnie', 17),\n",
       " ('Bailey', 17),\n",
       " ('Pepper', 16),\n",
       " ('Boy', 16),\n",
       " ('Jojo', 16),\n",
       " ('Cutie', 16),\n",
       " ('Milky', 15),\n",
       " ('Mocha', 15),\n",
       " ('Putih', 15),\n",
       " ('Unknown', 15),\n",
       " ('Jack', 14),\n",
       " ('Girl', 14),\n",
       " ('Grey', 14),\n",
       " ('Goldie', 14),\n",
       " ('Whitey', 13),\n",
       " ('Oren', 13),\n",
       " ('Phoebe', 13),\n",
       " ('Snoopy', 13),\n",
       " ('Candy', 13),\n",
       " ('Beauty', 12),\n",
       " ('Patches', 12),\n",
       " ('Sam', 12),\n",
       " ('Bambi', 12),\n",
       " ('Tiny', 12),\n",
       " ('Dolly', 12),\n",
       " ('Hazel', 12),\n",
       " ('Spotty', 12),\n",
       " ('Lilo', 12),\n",
       " ('Sophie', 12),\n",
       " ('Sunny', 12),\n",
       " ('Miko', 11),\n",
       " ('Lady', 11),\n",
       " ('Joey', 11),\n",
       " ('Poppy', 11),\n",
       " ('Choco', 11),\n",
       " ('Browny', 11),\n",
       " ('Puppies For Adoption', 11),\n",
       " ('Jerry', 11),\n",
       " ('Ben', 11),\n",
       " ('Nana', 11),\n",
       " ('Xiao Bai', 11),\n",
       " ('Mochi', 11),\n",
       " ('Orange', 11),\n",
       " ('Jackie', 11),\n",
       " ('Harry', 11),\n",
       " ('Abby', 11),\n",
       " ('Honey', 10),\n",
       " ('Ruby', 10),\n",
       " ('Missy', 10),\n",
       " ('Smokey', 10),\n",
       " ('Cotton', 10),\n",
       " ('Miu Miu', 10),\n",
       " ('Zorro', 10),\n",
       " ('Blue', 10),\n",
       " ('Romeo', 10),\n",
       " ('Snow White', 10),\n",
       " ('Meow Meow', 10),\n",
       " ('Bubu', 10),\n",
       " ('Foxy', 10),\n",
       " ('Gigi', 10),\n",
       " ('Black', 10),\n",
       " ('Oscar', 9),\n",
       " ('Latte', 9),\n",
       " ('Cici', 9),\n",
       " ('Mini', 9),\n",
       " ('Bunny', 9),\n",
       " ('Shih Tzu', 9),\n",
       " ('Pretty', 9),\n",
       " ('6 Puppies', 9),\n",
       " ('Mia', 9),\n",
       " ('Charcoal', 9),\n",
       " ('Spot', 9),\n",
       " ('Yellow', 9),\n",
       " ('Yoyo', 9),\n",
       " ('Summer', 9),\n",
       " ('Bingo', 9),\n",
       " ('Caramel', 9),\n",
       " ('Handsome', 9),\n",
       " ('Marley', 9),\n",
       " ('Comot', 9),\n",
       " ('Casper', 9),\n",
       " ('Tigger', 9),\n",
       " ('Husky', 9),\n",
       " ('Yoda', 9),\n",
       " ('Sandy', 9),\n",
       " ('Bruno', 9),\n",
       " ('Brandy', 9),\n",
       " ('Charlie', 9),\n",
       " ('Kitties', 8),\n",
       " ('BB', 8),\n",
       " ('Money', 8),\n",
       " ('QQ', 8),\n",
       " ('Chiko', 8),\n",
       " ('Pinky', 8),\n",
       " ('Bonnie', 8),\n",
       " ('Timmy', 8),\n",
       " ('Chocolate', 8),\n",
       " ('Apple', 8),\n",
       " ('Tabby', 8),\n",
       " ('Doggie', 8),\n",
       " ('Belle', 8),\n",
       " ('Chester', 8),\n",
       " ('Ash', 8),\n",
       " ('None', 8),\n",
       " ('Snowie', 8),\n",
       " ('Zoey', 8),\n",
       " ('Snowball', 8),\n",
       " ('Kopi', 8),\n",
       " ('Jessie', 8),\n",
       " ('Loki', 8),\n",
       " ('Nala', 8),\n",
       " ('Beagle', 8),\n",
       " ('Muffin', 8),\n",
       " ('Jimmy', 8),\n",
       " ('Meow', 8),\n",
       " ('Ah Boy', 8),\n",
       " ('Girl Girl', 8),\n",
       " ('Garfield', 7),\n",
       " ('Comel', 7),\n",
       " ('Kaka', 7),\n",
       " ('Scooby', 7),\n",
       " ('Jasper', 7),\n",
       " ('Butter', 7),\n",
       " ('Kitten For Adoption', 7),\n",
       " ('Kittens For Adoption', 7),\n",
       " ('Sammy', 7),\n",
       " ('Hero', 7),\n",
       " ('Batman', 7),\n",
       " ('Sweetie', 7),\n",
       " ('Creamy', 7),\n",
       " ('Misty', 7),\n",
       " ('George', 7),\n",
       " ('Rambo', 7),\n",
       " ('Pixie', 7),\n",
       " ('Rusty', 7),\n",
       " ('Cherry', 7),\n",
       " ('Julie', 7),\n",
       " ('Golden', 7),\n",
       " ('Puteh', 7),\n",
       " ('Benji', 7),\n",
       " ('Roxy', 7),\n",
       " ('Faith', 7),\n",
       " ('Fifi', 7),\n",
       " ('Patch', 7),\n",
       " ('Billy', 7),\n",
       " ('June', 7),\n",
       " ('Kiko', 7),\n",
       " ('Maya', 7),\n",
       " ('Jacky', 7),\n",
       " ('Pearl', 7),\n",
       " ('Boy Boy', 7),\n",
       " ('Grace', 7),\n",
       " ('Dexter', 7),\n",
       " ('Twinkle', 7),\n",
       " ('Mei Mei', 7),\n",
       " ('Cooper', 7),\n",
       " ('Mika', 7),\n",
       " ('Mojo', 7),\n",
       " ('Miki', 7),\n",
       " ('Amber', 7),\n",
       " ('Chloe', 7),\n",
       " ('Rex', 7),\n",
       " ('Dino', 7),\n",
       " ('Cute Puppies', 6),\n",
       " ('Sweety', 6),\n",
       " ('Wei Wei', 6),\n",
       " ('Shorty', 6),\n",
       " ('Sassy', 6),\n",
       " ('Socks', 6),\n",
       " ('Mylo', 6),\n",
       " ('Gizmo', 6),\n",
       " ('Kuro', 6),\n",
       " ('Xena', 6),\n",
       " ('Sasa', 6),\n",
       " ('Bosco', 6),\n",
       " ('Sasha', 6),\n",
       " ('Hope', 6),\n",
       " ('Dora', 6),\n",
       " ('Betty', 6),\n",
       " ('Rosie', 6),\n",
       " ('Xiao Hei', 6),\n",
       " ('Nancy', 6),\n",
       " ('Sushi', 6),\n",
       " ('Sparky', 6),\n",
       " ('Winter', 6),\n",
       " ('Yuki', 6),\n",
       " ('Suki', 6),\n",
       " ('Jenny', 6),\n",
       " ('Lala', 6),\n",
       " ('Marble', 6),\n",
       " ('Pluto', 6),\n",
       " ('Marco', 6),\n",
       " ('Amy', 6),\n",
       " ('Jill', 6),\n",
       " ('Pumpkin', 6),\n",
       " ('Terry', 6),\n",
       " ('Tammy', 6),\n",
       " ('Sugar', 6),\n",
       " ('Macy', 6),\n",
       " ('Callie', 6),\n",
       " ('MiMi', 6),\n",
       " ('Joe', 6),\n",
       " ('Nameless', 6),\n",
       " ('Zara', 6),\n",
       " ('Hunter', 5),\n",
       " ('Ollie', 5),\n",
       " ('Cody', 5),\n",
       " ('Manja', 5),\n",
       " ('Polly', 5),\n",
       " ('Ninja', 5),\n",
       " ('Goofy', 5),\n",
       " ('Maddie', 5),\n",
       " ('Baby Girl', 5),\n",
       " ('Koko', 5),\n",
       " ('Lassie', 5),\n",
       " ('Bubble', 5),\n",
       " ('Ming', 5),\n",
       " ('Unnamed', 5),\n",
       " ('Johnny', 5),\n",
       " ('Vodka', 5),\n",
       " ('Millie', 5),\n",
       " ('Hugo', 5),\n",
       " ('Shiro', 5),\n",
       " ('Layla', 5),\n",
       " ('Nicky', 5),\n",
       " ('Patchy', 5),\n",
       " ('Jasmine', 5),\n",
       " ('Dot', 5),\n",
       " ('Lovely Puppies', 5),\n",
       " ('Velvet', 5),\n",
       " ('Boboy', 5),\n",
       " ('Emily', 5),\n",
       " ('Tarzan', 5),\n",
       " ('Rascal', 5),\n",
       " ('Penny', 5),\n",
       " ('Belang', 5),\n",
       " ('Blu', 5),\n",
       " ('Jane', 5),\n",
       " ('Sally', 5),\n",
       " ('Dee Dee', 5),\n",
       " ('Didi', 5),\n",
       " ('Cheetah', 5),\n",
       " ('Mao Mao', 5),\n",
       " ('Elsa', 5),\n",
       " ('Tony', 5),\n",
       " ('Cheeky', 5),\n",
       " ('JoJo', 5),\n",
       " ('Monkey', 5),\n",
       " ('Bibi', 5),\n",
       " ('Cleo', 5),\n",
       " ('Casey', 5),\n",
       " ('Ginger Boy', 5),\n",
       " ('Lucas', 5),\n",
       " ('Eva', 5),\n",
       " ('2 Kittens', 5),\n",
       " ('Bessy', 5),\n",
       " ('Yuan Yuan', 5),\n",
       " ('4 Kittens', 5),\n",
       " ('Rooney', 5),\n",
       " ('Bubbles', 5),\n",
       " ('Snowflake', 5),\n",
       " ('Sky', 5),\n",
       " ('Vanilla', 5),\n",
       " ('Tam Tam', 5),\n",
       " ('Dodo', 5),\n",
       " ('Gucci', 5),\n",
       " ('John', 5),\n",
       " ('Bear', 4),\n",
       " ('Zoe', 4),\n",
       " ('Xiao Huang', 4),\n",
       " ('Cat', 4),\n",
       " ('Roscoe', 4),\n",
       " ('Tobby', 4),\n",
       " ('Murphy', 4),\n",
       " ('Mani', 4),\n",
       " ('Sunshine', 4),\n",
       " ('Puppy 2', 4),\n",
       " ('Junior', 4),\n",
       " ('Tompok', 4),\n",
       " ('Berry', 4),\n",
       " ('Cute Pups', 4),\n",
       " ('Lovely', 4),\n",
       " ('Poodle', 4),\n",
       " ('Samson', 4),\n",
       " ('Stella', 4),\n",
       " ('Squirrel', 4),\n",
       " ('Curly', 4),\n",
       " ('Polo', 4),\n",
       " ('Star', 4),\n",
       " ('Toto', 4),\n",
       " ('Furry', 4),\n",
       " ('Odie', 4),\n",
       " ('JJ', 4),\n",
       " ('Susie', 4),\n",
       " ('Doggy', 4),\n",
       " ('Black Beauty', 4),\n",
       " ('Clara', 4),\n",
       " ('Chanel', 4),\n",
       " ('Owen', 4),\n",
       " ('Mandy', 4),\n",
       " ('Dottie', 4),\n",
       " ('Ricky', 4),\n",
       " ('3 Kittens', 4),\n",
       " ('May', 4),\n",
       " ('Mummy', 4),\n",
       " ('Bee', 4),\n",
       " ('Xiao Mi', 4),\n",
       " ('Kenji', 4),\n",
       " ('Ringo', 4),\n",
       " ('Kit Kat', 4),\n",
       " ('Mama', 4),\n",
       " ('Leia', 4),\n",
       " ('3 Cute Kittens', 4),\n",
       " ('Elmo', 4),\n",
       " ('Pirate', 4),\n",
       " ('Abu', 4),\n",
       " ('No Names Yet', 4),\n",
       " ('Ace', 4),\n",
       " ('Utih', 4),\n",
       " ('Scotch', 4),\n",
       " ('Whiskey', 4),\n",
       " ('Alex', 4),\n",
       " ('Tyson', 4),\n",
       " ('Whisky', 4),\n",
       " ('Mumu', 4),\n",
       " ('Chico', 4),\n",
       " ('Rose', 4),\n",
       " ('Polar', 4),\n",
       " ('4 Kitten', 4),\n",
       " ('Bandit', 4),\n",
       " ('Bambee', 4),\n",
       " ('Sarah', 4),\n",
       " ('Gracie', 4),\n",
       " ('Cleopatra', 4),\n",
       " ('King', 4),\n",
       " ('5 Puppies', 4),\n",
       " ('Buffy', 4),\n",
       " ('Pebbles', 4),\n",
       " ('Lexi', 4),\n",
       " ('Eddy', 4),\n",
       " ('April', 4),\n",
       " ('Babies', 4),\n",
       " ('Robin', 4),\n",
       " ('Kimmy', 4),\n",
       " ('Teddy Bear', 4),\n",
       " ('Tara', 4),\n",
       " ('Caesar', 4),\n",
       " ('Dobby', 4),\n",
       " ('Cocoa', 4),\n",
       " ('Spike', 4),\n",
       " ('Baby Kittens', 4),\n",
       " ('Peaches', 4),\n",
       " ('Smiley', 4),\n",
       " ('Smarty', 4),\n",
       " ('Jacob', 4),\n",
       " ('Henry', 4),\n",
       " ('Fiona', 4),\n",
       " ('Venus', 4),\n",
       " ('Sesame', 4),\n",
       " ('Boo', 4),\n",
       " ('Garlic', 4),\n",
       " ('2 Puppies', 4),\n",
       " ('Jedi', 4),\n",
       " ('MJ', 4),\n",
       " ('Dot Dot', 4),\n",
       " ('CoCo', 4),\n",
       " ('B1', 4),\n",
       " ('Fat Boy', 4),\n",
       " ('Troy', 4),\n",
       " ('Rosco', 4),\n",
       " ('Olive', 4),\n",
       " ('B2', 4),\n",
       " ('Moo', 4),\n",
       " ('Ellie', 4),\n",
       " ('Little White', 4),\n",
       " ('Hachi', 4),\n",
       " ('Nemo', 4),\n",
       " ('Stripey', 4),\n",
       " ('Chelsea', 4),\n",
       " ('Ling Ling', 4),\n",
       " ('Jingle', 4),\n",
       " ('Einstein', 4),\n",
       " ('Bai Bai', 4),\n",
       " ('Sierra', 4),\n",
       " ('Hailey', 4),\n",
       " ('Bebe', 4),\n",
       " ('Pipi', 4),\n",
       " ('Donut', 3),\n",
       " ('Ding Ding', 3),\n",
       " ('Rocket', 3),\n",
       " ('Manis', 3),\n",
       " ('Harvey', 3),\n",
       " ('Meme', 3),\n",
       " ('Not Yet Named', 3),\n",
       " ('Carly', 3),\n",
       " ('Lemon', 3),\n",
       " ('Katniss', 3),\n",
       " ('2 Female Puppies', 3),\n",
       " ('Lovey', 3),\n",
       " ('Isabella', 3),\n",
       " ('Little', 3),\n",
       " ('Pepsi', 3),\n",
       " ('Gina', 3),\n",
       " ('Catty', 3),\n",
       " ('Tuah', 3),\n",
       " ('Blessing', 3),\n",
       " ('Chi Chi', 3),\n",
       " ('Male Puppy', 3),\n",
       " ('Django', 3),\n",
       " ('Tango', 3),\n",
       " ('Kuning', 3),\n",
       " ('Tofu', 3),\n",
       " ('Nero', 3),\n",
       " ('Munchkin', 3),\n",
       " ('Sweetheart', 3),\n",
       " ('Roger', 3),\n",
       " ('Sumi', 3),\n",
       " ('Sherlock', 3),\n",
       " ('Tom & Jerry', 3),\n",
       " ('Tiggy', 3),\n",
       " ('Ah Wong', 3),\n",
       " ('Precious', 3),\n",
       " ('Katie', 3),\n",
       " ('Ceaser', 3),\n",
       " ('Mary', 3),\n",
       " ('Yumi', 3),\n",
       " ('Vicky', 3),\n",
       " ('Boxer', 3),\n",
       " ('Felix', 3),\n",
       " ('MILO', 3),\n",
       " ('Stone', 3),\n",
       " ('Trixie', 3),\n",
       " ('Smoky', 3),\n",
       " ('White', 3),\n",
       " ('Cute Puppy', 3),\n",
       " ('Ella', 3),\n",
       " ('Darlie', 3),\n",
       " ('Wang Wang', 3),\n",
       " ('Sunday', 3),\n",
       " ('Girlie', 3),\n",
       " ('Lui Lui', 3),\n",
       " ('Jo Jo', 3),\n",
       " ('Little One', 3),\n",
       " ('Cindy', 3),\n",
       " ('Tasha', 3),\n",
       " ('Goldy', 3),\n",
       " ('Siblings', 3),\n",
       " ('Norman', 3),\n",
       " ('Maggie', 3),\n",
       " ('7 Puppies', 3),\n",
       " ('HAZEL', 3),\n",
       " ('Wolfie', 3),\n",
       " ('Barney', 3),\n",
       " ('Micky', 3),\n",
       " ('Charlotte', 3),\n",
       " ('Cute Kittens', 3),\n",
       " ('Mix Breed', 3),\n",
       " ('Bam Bam', 3),\n",
       " ('Emma', 3),\n",
       " ('Windy', 3),\n",
       " ('Salem', 3),\n",
       " ('Pishi', 3),\n",
       " ('Ebony', 3),\n",
       " ('Noname', 3),\n",
       " ('Cloudy', 3),\n",
       " ('Ginny', 3),\n",
       " ('Little Tiger', 3),\n",
       " ('Faye', 3),\n",
       " ('Bell', 3),\n",
       " ('Louise', 3),\n",
       " ('Shaggy', 3),\n",
       " ('Jay', 3),\n",
       " ('Puffy', 3),\n",
       " ('Lucky Boy', 3),\n",
       " ('Midnight', 3),\n",
       " ('Becky', 3),\n",
       " ('8 Puppies', 3),\n",
       " ('Toothless', 3),\n",
       " ('Britney', 3),\n",
       " ('Lion', 3),\n",
       " ('Christmas', 3),\n",
       " ('Playful', 3),\n",
       " ('Kitty For Adoption', 3),\n",
       " ('Truffle', 3),\n",
       " ('Gray', 3),\n",
       " ('Larry', 3),\n",
       " ('Elsie', 3),\n",
       " ('Brown', 3),\n",
       " ('Niki', 3),\n",
       " ('Adorable Pups For Adoption', 3),\n",
       " ('B', 3),\n",
       " ('Donna', 3),\n",
       " ('Dudu', 3),\n",
       " ('Tutu', 3),\n",
       " ('Louie', 3),\n",
       " ('Golden Retriever', 3),\n",
       " ('Donny', 3),\n",
       " ('Mac', 3),\n",
       " ('Shasha', 3),\n",
       " ('3 Musketeers', 3),\n",
       " ('James', 3),\n",
       " ('Arthur', 3),\n",
       " ('Handsome Boy', 3),\n",
       " ('Alfie', 3),\n",
       " ('Omey', 3),\n",
       " ('Hiro', 3),\n",
       " ('Kitten 1', 3),\n",
       " ('Duke', 3),\n",
       " ('Juju', 3),\n",
       " ('Rufus', 3),\n",
       " ('FLUFFY', 3),\n",
       " ('Citam', 3),\n",
       " ('A1', 3),\n",
       " ('Kelly', 3),\n",
       " ('Scott', 3),\n",
       " ('Cola', 3),\n",
       " ('Neslo', 3),\n",
       " ('Thunder', 3),\n",
       " ('Silky', 3),\n",
       " ('Kiwi', 3),\n",
       " ('Joy', 3),\n",
       " ('Blackey', 3),\n",
       " ('Brownies', 3),\n",
       " ('Calico', 3),\n",
       " ('Luke', 3),\n",
       " ('Expresso', 3),\n",
       " ('Scoopy', 3),\n",
       " ('Tuxie', 3),\n",
       " ('Thomas', 3),\n",
       " ('Mou Mou', 3),\n",
       " ('Boots', 3),\n",
       " ('Sha Sha', 3),\n",
       " ('GINGER', 3),\n",
       " ('Zeus', 3),\n",
       " ('Jack Jack', 3),\n",
       " ('Chewy', 3),\n",
       " ('Cesar', 3),\n",
       " ('5 Puppies For Adoption', 3),\n",
       " ('4 Puppies', 3),\n",
       " ('5 Kittens', 3),\n",
       " ('Theodore', 3),\n",
       " ('Juno', 3),\n",
       " ('Vanila', 3),\n",
       " ('Pearly', 3),\n",
       " ('Flower', 3),\n",
       " ('Pico', 3),\n",
       " ('Buttercup', 3),\n",
       " ('Don', 3),\n",
       " ('Scotty', 3),\n",
       " ('Chip', 3),\n",
       " ('Survivor', 3),\n",
       " ('Naughty', 3),\n",
       " ('Bunga', 3),\n",
       " ('Tyler', 3),\n",
       " ('Amelia', 3),\n",
       " ('Miaomiao', 3),\n",
       " ('Gaga', 3),\n",
       " ('Bolt', 3),\n",
       " ('3 Puppies', 3),\n",
       " ('Three Kittens', 3),\n",
       " ('T-Rex', 3),\n",
       " ('Blondie', 3),\n",
       " ('Diamond', 3),\n",
       " ('Boboi', 3),\n",
       " ('Boyboy', 3),\n",
       " ('Dog', 3),\n",
       " ('Momot', 3),\n",
       " ('Fatty', 3),\n",
       " ('Sparkle', 3),\n",
       " ('Maxie', 3),\n",
       " ('Tabitha', 3),\n",
       " ('Horlicks', 3),\n",
       " ('Scruffy', 3),\n",
       " ('Kaya', 3),\n",
       " ('Ben Ben', 3),\n",
       " ('Raisin', 3),\n",
       " ('Hitam', 3),\n",
       " ('Aiko', 3),\n",
       " ('A2', 3),\n",
       " ('Soya', 3),\n",
       " ('Brian', 3),\n",
       " ('Kecik', 3),\n",
       " ('Puppy 1', 3),\n",
       " ('Silver', 3),\n",
       " ('PUPPY', 3),\n",
       " ('Grumpy', 3),\n",
       " ('Nini', 3),\n",
       " ('Stray', 3),\n",
       " ('Moon', 3),\n",
       " ('Toffee', 3),\n",
       " ('Rainy', 3),\n",
       " ('Crystal', 3),\n",
       " ('Lemonade', 3),\n",
       " ('Moo Moo', 3),\n",
       " ('The 3 Musketeers', 3),\n",
       " ('Fay', 3),\n",
       " ('Tux', 3),\n",
       " ('Miley', 3),\n",
       " ('Wow Wow', 3),\n",
       " ('BULAT', 2),\n",
       " ('Kali', 2),\n",
       " ('Dusty', 2),\n",
       " ('Skippy', 2),\n",
       " ('QiQi', 2),\n",
       " ('HeiHei', 2),\n",
       " ('Fei Chai', 2),\n",
       " ('Sweetie Pie', 2),\n",
       " ('C', 2),\n",
       " ('Kaiser', 2),\n",
       " ('5 Cutie Kitty', 2),\n",
       " ('Winnie', 2),\n",
       " ('Nutella', 2),\n",
       " ('CUTIE', 2),\n",
       " ('PANDA', 2),\n",
       " ('Galaxy', 2),\n",
       " ('Jayden', 2),\n",
       " ('Ragdoll', 2),\n",
       " ('Bongo', 2),\n",
       " ('Flora', 2),\n",
       " ('Flash', 2),\n",
       " ('Apollo', 2),\n",
       " ('Rocco', 2),\n",
       " ('Carmen', 2),\n",
       " ('Yimmy', 2),\n",
       " ('Vader', 2),\n",
       " ('Randy', 2),\n",
       " ('White Socks', 2),\n",
       " ('Hayden', 2),\n",
       " ('Oliver', 2),\n",
       " ('Tiger Girl', 2),\n",
       " ('Giant', 2),\n",
       " ('Choko', 2),\n",
       " ('Kimberly', 2),\n",
       " ('Jessy', 2),\n",
       " ('Chika', 2),\n",
       " ('Peppermint', 2),\n",
       " ('LEO', 2),\n",
       " ('Sonia', 2),\n",
       " ('June June', 2),\n",
       " ('Duchess', 2),\n",
       " ('Bernie', 2),\n",
       " ('Willy', 2),\n",
       " ('BRUNO', 2),\n",
       " ('Stripe', 2),\n",
       " ('Mike', 2),\n",
       " ('Cobey', 2),\n",
       " ('Disney', 2),\n",
       " ('Wanda', 2),\n",
       " ('Ice', 2),\n",
       " ('Reena', 2),\n",
       " ('Tuxedo', 2),\n",
       " ('Roxie', 2),\n",
       " ('Kimi', 2),\n",
       " ('DD', 2),\n",
       " ('Messy', 2),\n",
       " ('Blue Eyes', 2),\n",
       " ('Runty', 2),\n",
       " ('Tora', 2),\n",
       " ('Lisa', 2),\n",
       " ('Dalmation', 2),\n",
       " ('LUCKY', 2),\n",
       " ('Mikio', 2),\n",
       " ('Dollar', 2),\n",
       " ('Along', 2),\n",
       " ('Musang', 2),\n",
       " ('BLOSSOM', 2),\n",
       " ('Caspian', 2),\n",
       " ('Curry', 2),\n",
       " ('Shark', 2),\n",
       " ('Sporty', 2),\n",
       " ('Mini B', 2),\n",
       " ('Jumper', 2),\n",
       " ('Abam', 2),\n",
       " ('Wally', 2),\n",
       " ('KIKI', 2),\n",
       " ('Katherine', 2),\n",
       " ('Kris', 2),\n",
       " ('Danny', 2),\n",
       " ('Hans', 2),\n",
       " ('Reese', 2),\n",
       " ('Puppy 4', 2),\n",
       " ('Booboo', 2),\n",
       " ('Stray Puppies', 2),\n",
       " ('GirlGirl', 2),\n",
       " ('BB Girl', 2),\n",
       " ('Freckles', 2),\n",
       " ('F1', 2),\n",
       " ('Stuart', 2),\n",
       " ('Isabelle', 2),\n",
       " ('Potato', 2),\n",
       " ('Mio', 2),\n",
       " ('Nico', 2),\n",
       " ('Jing Jing', 2),\n",
       " ('Wonder', 2),\n",
       " ('Kara', 2),\n",
       " ('Kiara', 2),\n",
       " ('Mina', 2),\n",
       " ('Dim Sum', 2),\n",
       " ('Jiji', 2),\n",
       " ('Mayo', 2),\n",
       " ('Mona', 2),\n",
       " ('Feisty', 2),\n",
       " ('Panthera', 2),\n",
       " ('Teddie', 2),\n",
       " ('Jaws', 2),\n",
       " ('Orange Boy', 2),\n",
       " ('Pikachu', 2),\n",
       " ('Milk', 2),\n",
       " ('Lennie', 2),\n",
       " ('3 Cute Pups', 2),\n",
       " ('Beckham', 2),\n",
       " ('Kyle', 2),\n",
       " ('Raven', 2),\n",
       " ('JUNIOR', 2),\n",
       " ('Lu Lu', 2),\n",
       " ('Nova', 2),\n",
       " ('Kenzo', 2),\n",
       " ('Little Kittens', 2),\n",
       " ('3 Kitties', 2),\n",
       " ('4 Little Kitties', 2),\n",
       " ('Ray', 2),\n",
       " ('Max Boy', 2),\n",
       " ('Lexie', 2),\n",
       " ('3 Cuties', 2),\n",
       " ('HuggieBoy', 2),\n",
       " ('Jazzy', 2),\n",
       " ('Brown Boy', 2),\n",
       " ('MuiMui', 2),\n",
       " ('Aboo', 2),\n",
       " ('The 3 Sisters', 2),\n",
       " ('Goodie', 2),\n",
       " ('Cutey', 2),\n",
       " ('MICKEY', 2),\n",
       " ('Christy', 2),\n",
       " ('Kitty Kitty', 2),\n",
       " ('Frosty', 2),\n",
       " ('Ali', 2),\n",
       " ('Ozzy', 2),\n",
       " ('Dylan', 2),\n",
       " ('Mask', 2),\n",
       " ('Marmalade', 2),\n",
       " ('Little Baby', 2),\n",
       " ('Kiera', 2),\n",
       " ('Snowhite', 2),\n",
       " ('Marshmallow', 2),\n",
       " ('Josie', 2),\n",
       " ('Fat Girl', 2),\n",
       " ('Feather', 2),\n",
       " ('Rolla', 2),\n",
       " ('Hana', 2),\n",
       " ('è\\x82¥è\\x82¥', 2),\n",
       " ('Zebra', 2),\n",
       " ('Remi', 2),\n",
       " ('B3', 2),\n",
       " ('TamTam', 2),\n",
       " ('Pebby', 2),\n",
       " ('Puma', 2),\n",
       " ('Cream', 2),\n",
       " ('Cally', 2),\n",
       " ('Cute Tabby Kitten', 2),\n",
       " ('Itam', 2),\n",
       " ('Dusky', 2),\n",
       " ('Michi', 2),\n",
       " ('A5', 2),\n",
       " ('Jet', 2),\n",
       " ('Mimi & Momo', 2),\n",
       " ('Sandra', 2),\n",
       " ('Suzy', 2),\n",
       " ('Bear Bear', 2),\n",
       " ('Winston', 2),\n",
       " ('Schnauzer', 2),\n",
       " ('Cassie', 2),\n",
       " ('Ann Ann', 2),\n",
       " ('Cream Poodle', 2),\n",
       " ('Olivia', 2),\n",
       " ('Key Key', 2),\n",
       " ('BiBi', 2),\n",
       " ('Basset Hound', 2),\n",
       " ('Mohawk', 2),\n",
       " ('Gentle', 2),\n",
       " ('GM', 2),\n",
       " ('XiaoMi', 2),\n",
       " ('Julie & Maya', 2),\n",
       " ('Nori', 2),\n",
       " ('Ranger', 2),\n",
       " ('Fluffy Luna', 2),\n",
       " ('Justin', 2),\n",
       " ('Riko', 2),\n",
       " ('Abbie', 2),\n",
       " ('Aslan', 2),\n",
       " ('Aki', 2),\n",
       " ('Baby Boo', 2),\n",
       " ('Austin', 2),\n",
       " ('Mei', 2),\n",
       " ('Poe', 2),\n",
       " ('Andy', 2),\n",
       " ('Barry', 2),\n",
       " ('Binky', 2),\n",
       " ('A4', 2),\n",
       " ('BoyBoy', 2),\n",
       " ('Autumn', 2),\n",
       " ('Houdini', 2),\n",
       " ('Jinggo', 2),\n",
       " ('Dumbo', 2),\n",
       " ('Baby Teddy', 2),\n",
       " ('Lex', 2),\n",
       " ('Maxy', 2),\n",
       " ('Isaac', 2),\n",
       " ('Guai Guai', 2),\n",
       " ('Hunt', 2),\n",
       " ('Shero', 2),\n",
       " ('BOY', 2),\n",
       " ('Buster', 2),\n",
       " ('Four Kittens', 2),\n",
       " ('Pudding', 2),\n",
       " ('Bacon', 2),\n",
       " ('Rum', 2),\n",
       " ('Bamboo', 2),\n",
       " ('Sausage', 2),\n",
       " ('Sundae', 2),\n",
       " ('Minion', 2),\n",
       " ('MOLLY', 2),\n",
       " ('Pony', 2),\n",
       " ('Boris', 2),\n",
       " ('Donnie', 2),\n",
       " ('Jimbo', 2),\n",
       " ('Tina', 2),\n",
       " ('Cute Kitten', 2),\n",
       " ('Meera', 2),\n",
       " ('Maxi', 2),\n",
       " ('American Cocker Spaniel', 2),\n",
       " ('Nina', 2),\n",
       " ('Melon', 2),\n",
       " ('Cashew', 2),\n",
       " ('Archie', 2),\n",
       " ('Tim', 2),\n",
       " ('Nil', 2),\n",
       " ('Black Rose', 2),\n",
       " ('Mushroom', 2),\n",
       " ('White Kitten', 2),\n",
       " ('Cappuccino', 2),\n",
       " ('Puppy For Adoption', 2),\n",
       " ('A3', 2),\n",
       " ('Gus', 2),\n",
       " ('Alicia', 2),\n",
       " ('Miao', 2),\n",
       " ('Naomi', 2),\n",
       " ('Not Named Yet', 2),\n",
       " ('Maria', 2),\n",
       " ('Pup', 2),\n",
       " ('Rabbit', 2),\n",
       " ('Nikko', 2),\n",
       " ('Wawa', 2),\n",
       " ('ROMEO', 2),\n",
       " ('Louis', 2),\n",
       " ('Champ', 2),\n",
       " ('Jellybean', 2),\n",
       " ('Sisi', 2),\n",
       " ('Liam', 2),\n",
       " ('Megan', 2),\n",
       " ('Bentley', 2),\n",
       " ('May May', 2),\n",
       " ('Toni', 2),\n",
       " ('Jolin', 2),\n",
       " ('Renny', 2),\n",
       " ('Pugsley', 2),\n",
       " ('Luckie', 2),\n",
       " ('Dio', 2),\n",
       " ('Pandora', 2),\n",
       " ('Dixie', 2),\n",
       " ('GG', 2),\n",
       " ('Mikey', 2),\n",
       " ('Lela', 2),\n",
       " ('Katy', 2),\n",
       " ('Athena', 2),\n",
       " ('Bella Girl', 2),\n",
       " ('Kira', 2),\n",
       " ('Rio', 2),\n",
       " ('Babe', 2),\n",
       " ('Ginger Kitten', 2),\n",
       " ('Jumbo', 2),\n",
       " ('Mo Mo', 2),\n",
       " ('Ming Ming', 2),\n",
       " ('Kiss', 2),\n",
       " ('Hazy', 2),\n",
       " ('Shiloh', 2),\n",
       " ('å°\\x8fé»\\x91', 2),\n",
       " ('B4', 2),\n",
       " ('Sean', 2),\n",
       " ('Oyien', 2),\n",
       " ('Hannah', 2),\n",
       " ('Heidi', 2),\n",
       " ('Samuel', 2),\n",
       " ('Colby', 2),\n",
       " ('(no Name)', 2),\n",
       " ('2 Cute Puppies', 2),\n",
       " ('Piko', 2),\n",
       " ('Coco Chanel', 2),\n",
       " ('Truffles', 2),\n",
       " ('Angah', 2),\n",
       " ('Debby', 2),\n",
       " ('Tuna', 2),\n",
       " ('Fafa', 2),\n",
       " ('Mango', 2),\n",
       " ('Ting Ting', 2),\n",
       " ('Spots', 2),\n",
       " ('Skit', 2),\n",
       " ('ROTTIE', 2),\n",
       " ('The Three Amigos', 2),\n",
       " ('Sayang', 2),\n",
       " ('Woofy', 2),\n",
       " ('Yuyu', 2),\n",
       " ('Michelle', 2),\n",
       " ('Tracy', 2),\n",
       " ('Miao Miao', 2),\n",
       " ('Puppy Brownie', 2),\n",
       " ('Debi', 2),\n",
       " ('Blackies', 2),\n",
       " ('Paris', 2),\n",
       " ('Anson', 2),\n",
       " ('Mixed Breed Puppies', 2),\n",
       " ('Copper', 2),\n",
       " ('Dada', 2),\n",
       " ('Melody', 2),\n",
       " ('Cutie Pie', 2),\n",
       " ('Coda', 2),\n",
       " ('Anya The Manja', 2),\n",
       " ('Puppy 3', 2),\n",
       " ('Fuji', 2),\n",
       " ('Fairy', 2),\n",
       " ('Xiao Xiao', 2),\n",
       " ('Wesley', 2),\n",
       " ('Awang', 2),\n",
       " ('Bi Bi', 2),\n",
       " ('Keiko', 2),\n",
       " ('Bouncy', 2),\n",
       " ('Ocha', 2),\n",
       " ('Kyra', 2),\n",
       " ('Tucker', 2),\n",
       " ('Ruffles', 2),\n",
       " ('Little Brown', 2),\n",
       " ('Mercy', 2),\n",
       " ('Alpha', 2),\n",
       " ('Kayla', 2),\n",
       " ('Annie', 2),\n",
       " ('Barnie', 2),\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(csv_dataset[\"Name\"].unique().shape)\n",
    "count = Counter(csv_dataset[\"Name\"].values.tolist())\n",
    "sorted_count = sorted(count.items(), key = lambda x: x[1], reverse = True)\n",
    "sorted_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e7ce9dda3d73fba01e8d15aec1bca18f41d699e8"
   },
   "source": [
    "## drop \"RescuerID\" and \"Name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9061,), (5595,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_dataset[\"Name\"].unique().shape, csv_dataset[\"RescuerID\"].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dataset.drop([\"RescuerID\",\"Name\",\"Description\"], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Type', 'Age', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n",
       "       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n",
       "       'Sterilized', 'Health', 'Quantity', 'Fee', 'State', 'VideoAmt',\n",
       "       'PhotoAmt', 'AdoptionSpeed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add nlp features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_abslute(sentences):\n",
    "    max_ = 0\n",
    "    real = 0\n",
    "    for sentence in sentences:\n",
    "        tmp = abs(sentence['sentiment']['score'])\n",
    "        if tmp > max_:\n",
    "            max_ = tmp\n",
    "            real = sentence['sentiment']['score'] * sentence['sentiment']['magnitude']\n",
    "    return real\n",
    "\n",
    "\n",
    "def get_min_abslute(sentences):\n",
    "    min_ = float(\"inf\")\n",
    "    real = 0\n",
    "    for sentence in sentences:\n",
    "        tmp = abs(sentence['sentiment']['score'])\n",
    "        if tmp < min_:\n",
    "            min_ = tmp\n",
    "            real = sentence['sentiment']['score'] * sentence['sentiment']['magnitude']\n",
    "    return real\n",
    "\n",
    "\n",
    "def get_mean_abslute(sentences):\n",
    "    sum_ = 0\n",
    "    count = 0\n",
    "    real = 0\n",
    "    for sentence in sentences:\n",
    "        sum_ += sentence['sentiment']['score'] * sentence['sentiment']['magnitude']\n",
    "        count += 1\n",
    "    \n",
    "    return sum_ / count\n",
    "    \n",
    "\n",
    "def func(value):\n",
    "    if type(value) == type(\"value\"):\n",
    "        return 0\n",
    "    else:\n",
    "        return value\n",
    "    \n",
    "    \n",
    "def get_sentiment_dict(path):\n",
    "    score_max = {}\n",
    "    score_min = {}\n",
    "    score_mean = {}\n",
    "    \n",
    "    document_score = {}\n",
    "    document_magnitude = {}\n",
    "\n",
    "    \n",
    "    \n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".json\"):\n",
    "            PetID = file.split(\".\")[0]\n",
    "            with open(path + file,\"r\") as f:\n",
    "                content = json.loads(f.read())\n",
    "\n",
    "            \n",
    "            score_max[PetID] = get_max_abslute(content['sentences'])\n",
    "            score_min[PetID] = get_min_abslute(content['sentences'])\n",
    "            score_mean[PetID] = get_mean_abslute(content['sentences'])\n",
    "            \n",
    "            document_score[PetID] = content['documentSentiment']['score']\n",
    "            document_magnitude[PetID] = content['documentSentiment']['magnitude']\n",
    "    \n",
    "    return score_max,score_min,score_mean,document_score,document_magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nlp_path = working_dir + \"/train_sentiment/\"\n",
    "score_max,score_min,score_mean,document_score,document_magnitude = get_sentiment_dict(train_nlp_path)\n",
    "\n",
    "\n",
    "csv_dataset[\"score_max\"] = csv_dataset.index\n",
    "csv_dataset[\"score_max\"] = csv_dataset[\"score_max\"].replace(score_max)\n",
    "csv_dataset[\"score_max\"] = csv_dataset[\"score_max\"].apply(func)\n",
    "\n",
    "csv_dataset[\"score_min\"] = csv_dataset.index\n",
    "csv_dataset[\"score_min\"] = csv_dataset[\"score_min\"].replace(score_min)\n",
    "csv_dataset[\"score_min\"] = csv_dataset[\"score_min\"].apply(func)\n",
    "\n",
    "\n",
    "csv_dataset[\"score_mean\"] = csv_dataset.index\n",
    "csv_dataset[\"score_mean\"] = csv_dataset[\"score_mean\"].replace(score_mean)\n",
    "csv_dataset[\"score_mean\"] = csv_dataset[\"score_mean\"].apply(func)\n",
    "\n",
    "\n",
    "csv_dataset[\"document_score\"] = csv_dataset.index\n",
    "csv_dataset[\"document_score\"] = csv_dataset[\"document_score\"].replace(document_score)\n",
    "csv_dataset[\"document_score\"] = csv_dataset[\"document_score\"].apply(func)\n",
    "\n",
    "\n",
    "csv_dataset[\"document_magnitude\"] = csv_dataset.index\n",
    "csv_dataset[\"document_magnitude\"] = csv_dataset[\"document_magnitude\"].replace(document_magnitude)\n",
    "csv_dataset[\"document_magnitude\"] = csv_dataset[\"document_magnitude\"].apply(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Type', 'Age', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n",
       "       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n",
       "       'Sterilized', 'Health', 'Quantity', 'Fee', 'State', 'VideoAmt',\n",
       "       'PhotoAmt', 'AdoptionSpeed', 'score_max', 'score_min', 'score_mean',\n",
       "       'document_score', 'document_magnitude'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dummy category features and standard numerical features\n",
    "\n",
    "1. category:  \n",
    "    ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',  \n",
    "    'Color3', 'Vaccinated', 'Dewormed', 'Sterilized', 'Health',  \n",
    "    'State','score_max', 'score_min', 'score_mean','document_score', 'document_magnitude']\n",
    "\n",
    "2. numerical:\n",
    "    ['Age','MaturitySize','FurLength', 'Quantity', 'Fee','VideoAmt', 'PhotoAmt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "numerical_features = ['Age','MaturitySize','FurLength', 'Quantity', 'Fee','VideoAmt', 'PhotoAmt','Breed1', 'Breed2','score_max', 'score_min', 'score_mean',\n",
    "       'document_score', 'document_magnitude']\n",
    "non_numerical_features = ['Type', 'Gender', 'Color1', 'Color2', 'Color3', 'Vaccinated', 'Dewormed', 'Sterilized', 'Health','State']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "csv_dataset.loc[:,numerical_features] = scaler.fit_transform(csv_dataset.loc[:,numerical_features])\n",
    "csv_dataset = pd.get_dummies(csv_dataset, dummy_na=True, columns = non_numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14993,), (14993, 75))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = csv_dataset[\"AdoptionSpeed\"]\n",
    "csv_dataset.drop(labels = [\"AdoptionSpeed\"], axis = 1, inplace=True)\n",
    "\n",
    "labels.shape, csv_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"labels.pkl\",\"wb\") as f:\n",
    "    pkl.dump(labels,f)\n",
    "\n",
    "with open(\"csv_dataset.pkl\",\"wb\") as f:\n",
    "    pkl.dump(csv_dataset,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a5ed6b982637>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best parameters set found on development set:\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    csv_dataset, labels, test_size=0.2, random_state=0)\n",
    "\n",
    "parameters = {\n",
    "    'gamma': [0.1,0,2],\n",
    "    'max_depth': [6,8,10,12],               \n",
    "    'subsample': [0.8,0.9,1.0],              \n",
    "    'colsample_bytree': [0.8,0.9,1.0],       \n",
    "    'min_child_weight': [3,5],\n",
    "    'eta': [0.001, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "        objective= 'multi:softmax',\n",
    "        reg_lambda= 2,                   \n",
    "        num_class = 5,\n",
    "        nthread = 4,\n",
    "        silent = 1,\n",
    ")\n",
    "\n",
    "model = GridSearchCV(model, parameters, n_jobs=-1, cv=5, scoring=\"accuracy\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Best parameters set found on development set:\\n\")\n",
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41347115705235077\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.08      0.60      0.14        10\n",
      "         1.0       0.34      0.39      0.36       573\n",
      "         2.0       0.41      0.35      0.38       935\n",
      "         3.0       0.24      0.39      0.30       397\n",
      "         4.0       0.64      0.49      0.56      1084\n",
      "\n",
      "   micro avg       0.41      0.41      0.41      2999\n",
      "   macro avg       0.34      0.44      0.35      2999\n",
      "weighted avg       0.46      0.41      0.43      2999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "print(sum(pred == y_test)/len(pred))\n",
    "print(classification_report(pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14993, 5)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_encoder = OneHotEncoder()\n",
    "one_hot_labels = labels_encoder.fit_transform(labels.values.reshape((labels.shape[0],1)))\n",
    "one_hot_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=100, input_dim= X_train.shape[1], activation = \"relu\"))\n",
    "model.add(Dropout(rate = 0.3))\n",
    "model.add(Dense(units=50,activation = \"relu\"))\n",
    "model.add(Dropout(rate = 0.5))\n",
    "model.add(Dense(units=20,activation = \"relu\"))\n",
    "model.add(Dropout(rate = 0.3))\n",
    "model.add(Dense(units=5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer= \"Adam\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11994 samples, validate on 2999 samples\n",
      "Epoch 1/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.2197 - acc: 0.4588 - val_loss: 1.4457 - val_acc: 0.3791\n",
      "Epoch 2/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.2190 - acc: 0.4548 - val_loss: 1.4439 - val_acc: 0.3811\n",
      "Epoch 3/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.2130 - acc: 0.4555 - val_loss: 1.4424 - val_acc: 0.3741\n",
      "Epoch 4/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.2113 - acc: 0.4628 - val_loss: 1.4475 - val_acc: 0.3821\n",
      "Epoch 5/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.2084 - acc: 0.4663 - val_loss: 1.4550 - val_acc: 0.3781\n",
      "Epoch 6/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.2069 - acc: 0.4630 - val_loss: 1.4481 - val_acc: 0.3691\n",
      "Epoch 7/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.2211 - acc: 0.4541 - val_loss: 1.4417 - val_acc: 0.3738\n",
      "Epoch 8/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.2129 - acc: 0.4591 - val_loss: 1.4503 - val_acc: 0.3718\n",
      "Epoch 9/500\n",
      "11994/11994 [==============================] - 0s 24us/step - loss: 1.2183 - acc: 0.4610 - val_loss: 1.4424 - val_acc: 0.3655\n",
      "Epoch 10/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.2085 - acc: 0.4636 - val_loss: 1.4492 - val_acc: 0.3721\n",
      "Epoch 11/500\n",
      "11994/11994 [==============================] - 0s 22us/step - loss: 1.2104 - acc: 0.4555 - val_loss: 1.4433 - val_acc: 0.3721\n",
      "Epoch 12/500\n",
      "11994/11994 [==============================] - 0s 29us/step - loss: 1.2042 - acc: 0.4622 - val_loss: 1.4470 - val_acc: 0.3715\n",
      "Epoch 13/500\n",
      "11994/11994 [==============================] - 0s 26us/step - loss: 1.2119 - acc: 0.4616 - val_loss: 1.4439 - val_acc: 0.3708\n",
      "Epoch 14/500\n",
      "11994/11994 [==============================] - 0s 22us/step - loss: 1.2094 - acc: 0.4660 - val_loss: 1.4520 - val_acc: 0.3765\n",
      "Epoch 15/500\n",
      "11994/11994 [==============================] - 1s 47us/step - loss: 1.2056 - acc: 0.4691 - val_loss: 1.4495 - val_acc: 0.3728\n",
      "Epoch 16/500\n",
      "11994/11994 [==============================] - 0s 24us/step - loss: 1.2039 - acc: 0.4707 - val_loss: 1.4475 - val_acc: 0.3738\n",
      "Epoch 17/500\n",
      "11994/11994 [==============================] - 0s 23us/step - loss: 1.2058 - acc: 0.4680 - val_loss: 1.4525 - val_acc: 0.3721\n",
      "Epoch 18/500\n",
      "11994/11994 [==============================] - 0s 22us/step - loss: 1.2081 - acc: 0.4658 - val_loss: 1.4482 - val_acc: 0.3748\n",
      "Epoch 19/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.2062 - acc: 0.4611 - val_loss: 1.4543 - val_acc: 0.3785\n",
      "Epoch 20/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.2055 - acc: 0.4667 - val_loss: 1.4479 - val_acc: 0.3718\n",
      "Epoch 21/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.2031 - acc: 0.4661 - val_loss: 1.4468 - val_acc: 0.3758\n",
      "Epoch 22/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.2025 - acc: 0.4666 - val_loss: 1.4458 - val_acc: 0.3761\n",
      "Epoch 23/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1997 - acc: 0.4705 - val_loss: 1.4442 - val_acc: 0.3761\n",
      "Epoch 24/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.2014 - acc: 0.4684 - val_loss: 1.4495 - val_acc: 0.3808\n",
      "Epoch 25/500\n",
      "11994/11994 [==============================] - 0s 23us/step - loss: 1.2054 - acc: 0.4633 - val_loss: 1.4499 - val_acc: 0.3811\n",
      "Epoch 26/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.2040 - acc: 0.4701 - val_loss: 1.4429 - val_acc: 0.3805\n",
      "Epoch 27/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.2070 - acc: 0.4672 - val_loss: 1.4483 - val_acc: 0.3811\n",
      "Epoch 28/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.2037 - acc: 0.4654 - val_loss: 1.4514 - val_acc: 0.3798\n",
      "Epoch 29/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1990 - acc: 0.4712 - val_loss: 1.4515 - val_acc: 0.3811\n",
      "Epoch 30/500\n",
      "11994/11994 [==============================] - 0s 37us/step - loss: 1.1935 - acc: 0.4799 - val_loss: 1.4505 - val_acc: 0.3715\n",
      "Epoch 31/500\n",
      "11994/11994 [==============================] - 0s 25us/step - loss: 1.2078 - acc: 0.4666 - val_loss: 1.4456 - val_acc: 0.3755\n",
      "Epoch 32/500\n",
      "11994/11994 [==============================] - 0s 23us/step - loss: 1.2022 - acc: 0.4689 - val_loss: 1.4504 - val_acc: 0.3791\n",
      "Epoch 33/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.2041 - acc: 0.4684 - val_loss: 1.4538 - val_acc: 0.3788\n",
      "Epoch 34/500\n",
      "11994/11994 [==============================] - 0s 23us/step - loss: 1.2071 - acc: 0.4626 - val_loss: 1.4501 - val_acc: 0.3795\n",
      "Epoch 35/500\n",
      "11994/11994 [==============================] - 0s 24us/step - loss: 1.2046 - acc: 0.4676 - val_loss: 1.4493 - val_acc: 0.3768\n",
      "Epoch 36/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.2011 - acc: 0.4734 - val_loss: 1.4502 - val_acc: 0.3751\n",
      "Epoch 37/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1963 - acc: 0.4712 - val_loss: 1.4518 - val_acc: 0.3791\n",
      "Epoch 38/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1932 - acc: 0.4751 - val_loss: 1.4608 - val_acc: 0.3758\n",
      "Epoch 39/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1957 - acc: 0.4712 - val_loss: 1.4500 - val_acc: 0.3791\n",
      "Epoch 40/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.2014 - acc: 0.4723 - val_loss: 1.4488 - val_acc: 0.3695\n",
      "Epoch 41/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.2030 - acc: 0.4661 - val_loss: 1.4550 - val_acc: 0.3778\n",
      "Epoch 42/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.2011 - acc: 0.4721 - val_loss: 1.4476 - val_acc: 0.3775\n",
      "Epoch 43/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.2025 - acc: 0.4645 - val_loss: 1.4529 - val_acc: 0.3765\n",
      "Epoch 44/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.2012 - acc: 0.4666 - val_loss: 1.4473 - val_acc: 0.3741\n",
      "Epoch 45/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1964 - acc: 0.4723 - val_loss: 1.4499 - val_acc: 0.3741\n",
      "Epoch 46/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1938 - acc: 0.4720 - val_loss: 1.4547 - val_acc: 0.3771\n",
      "Epoch 47/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1955 - acc: 0.4782 - val_loss: 1.4511 - val_acc: 0.3738\n",
      "Epoch 48/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.2044 - acc: 0.4696 - val_loss: 1.4492 - val_acc: 0.3768\n",
      "Epoch 49/500\n",
      "11994/11994 [==============================] - 0s 23us/step - loss: 1.1906 - acc: 0.4766 - val_loss: 1.4539 - val_acc: 0.3818\n",
      "Epoch 50/500\n",
      "11994/11994 [==============================] - 0s 22us/step - loss: 1.1928 - acc: 0.4710 - val_loss: 1.4532 - val_acc: 0.3818\n",
      "Epoch 51/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1971 - acc: 0.4687 - val_loss: 1.4576 - val_acc: 0.3715\n",
      "Epoch 52/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1972 - acc: 0.4692 - val_loss: 1.4587 - val_acc: 0.3755\n",
      "Epoch 53/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1941 - acc: 0.4707 - val_loss: 1.4530 - val_acc: 0.3721\n",
      "Epoch 54/500\n",
      "11994/11994 [==============================] - 0s 23us/step - loss: 1.1964 - acc: 0.4747 - val_loss: 1.4520 - val_acc: 0.3761\n",
      "Epoch 55/500\n",
      "11994/11994 [==============================] - 0s 24us/step - loss: 1.1904 - acc: 0.4701 - val_loss: 1.4602 - val_acc: 0.3738\n",
      "Epoch 56/500\n",
      "11994/11994 [==============================] - 0s 23us/step - loss: 1.1952 - acc: 0.4724 - val_loss: 1.4599 - val_acc: 0.3775\n",
      "Epoch 57/500\n",
      "11994/11994 [==============================] - 0s 23us/step - loss: 1.2011 - acc: 0.4658 - val_loss: 1.4595 - val_acc: 0.3741\n",
      "Epoch 58/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1960 - acc: 0.4747 - val_loss: 1.4506 - val_acc: 0.3765\n",
      "Epoch 59/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1981 - acc: 0.4698 - val_loss: 1.4513 - val_acc: 0.3725\n",
      "Epoch 60/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1935 - acc: 0.4713 - val_loss: 1.4562 - val_acc: 0.3751\n",
      "Epoch 61/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1927 - acc: 0.4727 - val_loss: 1.4576 - val_acc: 0.3758\n",
      "Epoch 62/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1950 - acc: 0.4689 - val_loss: 1.4637 - val_acc: 0.3791\n",
      "Epoch 63/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1918 - acc: 0.4697 - val_loss: 1.4559 - val_acc: 0.3775\n",
      "Epoch 64/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1901 - acc: 0.4707 - val_loss: 1.4569 - val_acc: 0.3788\n",
      "Epoch 65/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1924 - acc: 0.4737 - val_loss: 1.4530 - val_acc: 0.3841\n",
      "Epoch 66/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1909 - acc: 0.4740 - val_loss: 1.4573 - val_acc: 0.3775\n",
      "Epoch 67/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1877 - acc: 0.4754 - val_loss: 1.4560 - val_acc: 0.3768\n",
      "Epoch 68/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1863 - acc: 0.4784 - val_loss: 1.4599 - val_acc: 0.3805\n",
      "Epoch 69/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1864 - acc: 0.4768 - val_loss: 1.4570 - val_acc: 0.3805\n",
      "Epoch 70/500\n",
      "11994/11994 [==============================] - 0s 22us/step - loss: 1.1970 - acc: 0.4739 - val_loss: 1.4525 - val_acc: 0.3758\n",
      "Epoch 71/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1899 - acc: 0.4735 - val_loss: 1.4524 - val_acc: 0.3738\n",
      "Epoch 72/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1871 - acc: 0.4753 - val_loss: 1.4526 - val_acc: 0.3765\n",
      "Epoch 73/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1870 - acc: 0.4741 - val_loss: 1.4592 - val_acc: 0.3715\n",
      "Epoch 74/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1934 - acc: 0.4760 - val_loss: 1.4529 - val_acc: 0.3768\n",
      "Epoch 75/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1894 - acc: 0.4764 - val_loss: 1.4560 - val_acc: 0.3795\n",
      "Epoch 76/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1867 - acc: 0.4783 - val_loss: 1.4626 - val_acc: 0.3715\n",
      "Epoch 77/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1920 - acc: 0.4722 - val_loss: 1.4517 - val_acc: 0.3741\n",
      "Epoch 78/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1820 - acc: 0.4754 - val_loss: 1.4555 - val_acc: 0.3721\n",
      "Epoch 79/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1900 - acc: 0.4724 - val_loss: 1.4575 - val_acc: 0.3708\n",
      "Epoch 80/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1840 - acc: 0.4733 - val_loss: 1.4635 - val_acc: 0.3715\n",
      "Epoch 81/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1798 - acc: 0.4745 - val_loss: 1.4611 - val_acc: 0.3735\n",
      "Epoch 82/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1880 - acc: 0.4752 - val_loss: 1.4620 - val_acc: 0.3738\n",
      "Epoch 83/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1820 - acc: 0.4767 - val_loss: 1.4610 - val_acc: 0.3785\n",
      "Epoch 84/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1808 - acc: 0.4780 - val_loss: 1.4652 - val_acc: 0.3808\n",
      "Epoch 85/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1903 - acc: 0.4738 - val_loss: 1.4635 - val_acc: 0.3668\n",
      "Epoch 86/500\n",
      "11994/11994 [==============================] - 0s 18us/step - loss: 1.1791 - acc: 0.4807 - val_loss: 1.4722 - val_acc: 0.3685\n",
      "Epoch 87/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1813 - acc: 0.4818 - val_loss: 1.4670 - val_acc: 0.3761\n",
      "Epoch 88/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1877 - acc: 0.4767 - val_loss: 1.4658 - val_acc: 0.3815\n",
      "Epoch 89/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1858 - acc: 0.4738 - val_loss: 1.4617 - val_acc: 0.3741\n",
      "Epoch 90/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1839 - acc: 0.4757 - val_loss: 1.4664 - val_acc: 0.3781\n",
      "Epoch 91/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1851 - acc: 0.4765 - val_loss: 1.4596 - val_acc: 0.3765\n",
      "Epoch 92/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1836 - acc: 0.4804 - val_loss: 1.4641 - val_acc: 0.3755\n",
      "Epoch 93/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1926 - acc: 0.4720 - val_loss: 1.4572 - val_acc: 0.3771\n",
      "Epoch 94/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1904 - acc: 0.4792 - val_loss: 1.4595 - val_acc: 0.3781\n",
      "Epoch 95/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1909 - acc: 0.4772 - val_loss: 1.4592 - val_acc: 0.3795\n",
      "Epoch 96/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1891 - acc: 0.4732 - val_loss: 1.4613 - val_acc: 0.3785\n",
      "Epoch 97/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1849 - acc: 0.4789 - val_loss: 1.4662 - val_acc: 0.3798\n",
      "Epoch 98/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1782 - acc: 0.4778 - val_loss: 1.4610 - val_acc: 0.3748\n",
      "Epoch 99/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1835 - acc: 0.4807 - val_loss: 1.4595 - val_acc: 0.3718\n",
      "Epoch 100/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1760 - acc: 0.4793 - val_loss: 1.4723 - val_acc: 0.3731\n",
      "Epoch 101/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1763 - acc: 0.4799 - val_loss: 1.4678 - val_acc: 0.3705\n",
      "Epoch 102/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1896 - acc: 0.4761 - val_loss: 1.4605 - val_acc: 0.3725\n",
      "Epoch 103/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1856 - acc: 0.4740 - val_loss: 1.4634 - val_acc: 0.3741\n",
      "Epoch 104/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1835 - acc: 0.4792 - val_loss: 1.4649 - val_acc: 0.3755\n",
      "Epoch 105/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1815 - acc: 0.4837 - val_loss: 1.4674 - val_acc: 0.3718\n",
      "Epoch 106/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1833 - acc: 0.4798 - val_loss: 1.4636 - val_acc: 0.3745\n",
      "Epoch 107/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1833 - acc: 0.4762 - val_loss: 1.4645 - val_acc: 0.3775\n",
      "Epoch 108/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1853 - acc: 0.4777 - val_loss: 1.4603 - val_acc: 0.3758\n",
      "Epoch 109/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1807 - acc: 0.4755 - val_loss: 1.4691 - val_acc: 0.3731\n",
      "Epoch 110/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1783 - acc: 0.4764 - val_loss: 1.4662 - val_acc: 0.3725\n",
      "Epoch 111/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1777 - acc: 0.4796 - val_loss: 1.4654 - val_acc: 0.3691\n",
      "Epoch 112/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1778 - acc: 0.4775 - val_loss: 1.4724 - val_acc: 0.3748\n",
      "Epoch 113/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1778 - acc: 0.4782 - val_loss: 1.4709 - val_acc: 0.3818\n",
      "Epoch 114/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1855 - acc: 0.4743 - val_loss: 1.4630 - val_acc: 0.3791\n",
      "Epoch 115/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1799 - acc: 0.4782 - val_loss: 1.4687 - val_acc: 0.3825\n",
      "Epoch 116/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1793 - acc: 0.4782 - val_loss: 1.4669 - val_acc: 0.3738\n",
      "Epoch 117/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1727 - acc: 0.4779 - val_loss: 1.4680 - val_acc: 0.3791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1745 - acc: 0.4837 - val_loss: 1.4726 - val_acc: 0.3768\n",
      "Epoch 119/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1744 - acc: 0.4803 - val_loss: 1.4761 - val_acc: 0.3721\n",
      "Epoch 120/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1716 - acc: 0.4831 - val_loss: 1.4768 - val_acc: 0.3761\n",
      "Epoch 121/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1787 - acc: 0.4787 - val_loss: 1.4673 - val_acc: 0.3721\n",
      "Epoch 122/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1776 - acc: 0.4783 - val_loss: 1.4702 - val_acc: 0.3825\n",
      "Epoch 123/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1763 - acc: 0.4840 - val_loss: 1.4737 - val_acc: 0.3721\n",
      "Epoch 124/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1781 - acc: 0.4796 - val_loss: 1.4641 - val_acc: 0.3781\n",
      "Epoch 125/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1776 - acc: 0.4825 - val_loss: 1.4698 - val_acc: 0.3718\n",
      "Epoch 126/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1728 - acc: 0.4889 - val_loss: 1.4724 - val_acc: 0.3831\n",
      "Epoch 127/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1819 - acc: 0.4764 - val_loss: 1.4736 - val_acc: 0.3771\n",
      "Epoch 128/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1788 - acc: 0.4789 - val_loss: 1.4610 - val_acc: 0.3731\n",
      "Epoch 129/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1701 - acc: 0.4902 - val_loss: 1.4758 - val_acc: 0.3768\n",
      "Epoch 130/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1748 - acc: 0.4802 - val_loss: 1.4679 - val_acc: 0.3745\n",
      "Epoch 131/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1772 - acc: 0.4852 - val_loss: 1.4740 - val_acc: 0.3741\n",
      "Epoch 132/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1782 - acc: 0.4805 - val_loss: 1.4707 - val_acc: 0.3818\n",
      "Epoch 133/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1784 - acc: 0.4778 - val_loss: 1.4698 - val_acc: 0.3675\n",
      "Epoch 134/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1751 - acc: 0.4857 - val_loss: 1.4756 - val_acc: 0.3778\n",
      "Epoch 135/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1744 - acc: 0.4832 - val_loss: 1.4725 - val_acc: 0.3725\n",
      "Epoch 136/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1743 - acc: 0.4831 - val_loss: 1.4802 - val_acc: 0.3758\n",
      "Epoch 137/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1785 - acc: 0.4822 - val_loss: 1.4748 - val_acc: 0.3751\n",
      "Epoch 138/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1778 - acc: 0.4791 - val_loss: 1.4724 - val_acc: 0.3788\n",
      "Epoch 139/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1760 - acc: 0.4901 - val_loss: 1.4713 - val_acc: 0.3748\n",
      "Epoch 140/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1729 - acc: 0.4779 - val_loss: 1.4718 - val_acc: 0.3698\n",
      "Epoch 141/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1760 - acc: 0.4787 - val_loss: 1.4769 - val_acc: 0.3731\n",
      "Epoch 142/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1770 - acc: 0.4807 - val_loss: 1.4652 - val_acc: 0.3788\n",
      "Epoch 143/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1734 - acc: 0.4828 - val_loss: 1.4754 - val_acc: 0.3691\n",
      "Epoch 144/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1693 - acc: 0.4836 - val_loss: 1.4738 - val_acc: 0.3701\n",
      "Epoch 145/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1677 - acc: 0.4888 - val_loss: 1.4815 - val_acc: 0.3731\n",
      "Epoch 146/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1799 - acc: 0.4843 - val_loss: 1.4676 - val_acc: 0.3691\n",
      "Epoch 147/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1828 - acc: 0.4767 - val_loss: 1.4644 - val_acc: 0.3748\n",
      "Epoch 148/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1726 - acc: 0.4807 - val_loss: 1.4744 - val_acc: 0.3695\n",
      "Epoch 149/500\n",
      "11994/11994 [==============================] - 0s 18us/step - loss: 1.1709 - acc: 0.4818 - val_loss: 1.4752 - val_acc: 0.3721\n",
      "Epoch 150/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1733 - acc: 0.4839 - val_loss: 1.4778 - val_acc: 0.3748\n",
      "Epoch 151/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1792 - acc: 0.4786 - val_loss: 1.4777 - val_acc: 0.3705\n",
      "Epoch 152/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1714 - acc: 0.4835 - val_loss: 1.4715 - val_acc: 0.3755\n",
      "Epoch 153/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1712 - acc: 0.4832 - val_loss: 1.4754 - val_acc: 0.3735\n",
      "Epoch 154/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1709 - acc: 0.4820 - val_loss: 1.4718 - val_acc: 0.3778\n",
      "Epoch 155/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1707 - acc: 0.4827 - val_loss: 1.4747 - val_acc: 0.3755\n",
      "Epoch 156/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1666 - acc: 0.4826 - val_loss: 1.4735 - val_acc: 0.3748\n",
      "Epoch 157/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1747 - acc: 0.4817 - val_loss: 1.4704 - val_acc: 0.3775\n",
      "Epoch 158/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1692 - acc: 0.4892 - val_loss: 1.4741 - val_acc: 0.3795\n",
      "Epoch 159/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1730 - acc: 0.4874 - val_loss: 1.4743 - val_acc: 0.3758\n",
      "Epoch 160/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1749 - acc: 0.4822 - val_loss: 1.4786 - val_acc: 0.3768\n",
      "Epoch 161/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1709 - acc: 0.4845 - val_loss: 1.4779 - val_acc: 0.3725\n",
      "Epoch 162/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1714 - acc: 0.4785 - val_loss: 1.4732 - val_acc: 0.3688\n",
      "Epoch 163/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1636 - acc: 0.4874 - val_loss: 1.4775 - val_acc: 0.3671\n",
      "Epoch 164/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1681 - acc: 0.4890 - val_loss: 1.4816 - val_acc: 0.3691\n",
      "Epoch 165/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1766 - acc: 0.4797 - val_loss: 1.4748 - val_acc: 0.3745\n",
      "Epoch 166/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1724 - acc: 0.4809 - val_loss: 1.4774 - val_acc: 0.3761\n",
      "Epoch 167/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1665 - acc: 0.4836 - val_loss: 1.4859 - val_acc: 0.3751\n",
      "Epoch 168/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1686 - acc: 0.4871 - val_loss: 1.4709 - val_acc: 0.3745\n",
      "Epoch 169/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1703 - acc: 0.4846 - val_loss: 1.4835 - val_acc: 0.3731\n",
      "Epoch 170/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1673 - acc: 0.4840 - val_loss: 1.4729 - val_acc: 0.3771\n",
      "Epoch 171/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1713 - acc: 0.4821 - val_loss: 1.4799 - val_acc: 0.3731\n",
      "Epoch 172/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1681 - acc: 0.4795 - val_loss: 1.4811 - val_acc: 0.3795\n",
      "Epoch 173/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1669 - acc: 0.4888 - val_loss: 1.4876 - val_acc: 0.3788\n",
      "Epoch 174/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1735 - acc: 0.4787 - val_loss: 1.4778 - val_acc: 0.3738\n",
      "Epoch 175/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1700 - acc: 0.4857 - val_loss: 1.4788 - val_acc: 0.3745\n",
      "Epoch 176/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1732 - acc: 0.4818 - val_loss: 1.4775 - val_acc: 0.3761\n",
      "Epoch 177/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1615 - acc: 0.4862 - val_loss: 1.4841 - val_acc: 0.3781\n",
      "Epoch 178/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1733 - acc: 0.4846 - val_loss: 1.4810 - val_acc: 0.3758\n",
      "Epoch 179/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1681 - acc: 0.4868 - val_loss: 1.4829 - val_acc: 0.3671\n",
      "Epoch 180/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1694 - acc: 0.4822 - val_loss: 1.4879 - val_acc: 0.3758\n",
      "Epoch 181/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1635 - acc: 0.4925 - val_loss: 1.4863 - val_acc: 0.3661\n",
      "Epoch 182/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1647 - acc: 0.4882 - val_loss: 1.4907 - val_acc: 0.3681\n",
      "Epoch 183/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1747 - acc: 0.4787 - val_loss: 1.4869 - val_acc: 0.3728\n",
      "Epoch 184/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1699 - acc: 0.4843 - val_loss: 1.4893 - val_acc: 0.3708\n",
      "Epoch 185/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1654 - acc: 0.4837 - val_loss: 1.4866 - val_acc: 0.3681\n",
      "Epoch 186/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1590 - acc: 0.4949 - val_loss: 1.4926 - val_acc: 0.3748\n",
      "Epoch 187/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1676 - acc: 0.4925 - val_loss: 1.4881 - val_acc: 0.3728\n",
      "Epoch 188/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1741 - acc: 0.4780 - val_loss: 1.4837 - val_acc: 0.3725\n",
      "Epoch 189/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1667 - acc: 0.4866 - val_loss: 1.4864 - val_acc: 0.3715\n",
      "Epoch 190/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1688 - acc: 0.4815 - val_loss: 1.4921 - val_acc: 0.3735\n",
      "Epoch 191/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1548 - acc: 0.4920 - val_loss: 1.4957 - val_acc: 0.3715\n",
      "Epoch 192/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1611 - acc: 0.4884 - val_loss: 1.4927 - val_acc: 0.3721\n",
      "Epoch 193/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1730 - acc: 0.4850 - val_loss: 1.4922 - val_acc: 0.3731\n",
      "Epoch 194/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1636 - acc: 0.4887 - val_loss: 1.4856 - val_acc: 0.3721\n",
      "Epoch 195/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1717 - acc: 0.4843 - val_loss: 1.4797 - val_acc: 0.3765\n",
      "Epoch 196/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1597 - acc: 0.4898 - val_loss: 1.4837 - val_acc: 0.3741\n",
      "Epoch 197/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1644 - acc: 0.4833 - val_loss: 1.4878 - val_acc: 0.3718\n",
      "Epoch 198/500\n",
      "11994/11994 [==============================] - 0s 22us/step - loss: 1.1623 - acc: 0.4887 - val_loss: 1.4889 - val_acc: 0.3718\n",
      "Epoch 199/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1601 - acc: 0.4897 - val_loss: 1.4958 - val_acc: 0.3755\n",
      "Epoch 200/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1622 - acc: 0.4912 - val_loss: 1.4878 - val_acc: 0.3708\n",
      "Epoch 201/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1658 - acc: 0.4841 - val_loss: 1.4914 - val_acc: 0.3688\n",
      "Epoch 202/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1702 - acc: 0.4848 - val_loss: 1.4891 - val_acc: 0.3725\n",
      "Epoch 203/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1724 - acc: 0.4837 - val_loss: 1.4821 - val_acc: 0.3688\n",
      "Epoch 204/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1648 - acc: 0.4896 - val_loss: 1.4829 - val_acc: 0.3701\n",
      "Epoch 205/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1627 - acc: 0.4927 - val_loss: 1.4789 - val_acc: 0.3778\n",
      "Epoch 206/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1627 - acc: 0.4847 - val_loss: 1.4818 - val_acc: 0.3715\n",
      "Epoch 207/500\n",
      "11994/11994 [==============================] - 0s 22us/step - loss: 1.1635 - acc: 0.4902 - val_loss: 1.4861 - val_acc: 0.3751\n",
      "Epoch 208/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1627 - acc: 0.4848 - val_loss: 1.4854 - val_acc: 0.3795\n",
      "Epoch 209/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1663 - acc: 0.4842 - val_loss: 1.4907 - val_acc: 0.3735\n",
      "Epoch 210/500\n",
      "11994/11994 [==============================] - 0s 23us/step - loss: 1.1621 - acc: 0.4917 - val_loss: 1.4879 - val_acc: 0.3691\n",
      "Epoch 211/500\n",
      "11994/11994 [==============================] - 0s 22us/step - loss: 1.1644 - acc: 0.4858 - val_loss: 1.4860 - val_acc: 0.3791\n",
      "Epoch 212/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1635 - acc: 0.4928 - val_loss: 1.4902 - val_acc: 0.3778\n",
      "Epoch 213/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1581 - acc: 0.4882 - val_loss: 1.4939 - val_acc: 0.3711\n",
      "Epoch 214/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1638 - acc: 0.4882 - val_loss: 1.4945 - val_acc: 0.3741\n",
      "Epoch 215/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1576 - acc: 0.4938 - val_loss: 1.4959 - val_acc: 0.3771\n",
      "Epoch 216/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1587 - acc: 0.4847 - val_loss: 1.5024 - val_acc: 0.3765\n",
      "Epoch 217/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1620 - acc: 0.4933 - val_loss: 1.4979 - val_acc: 0.3765\n",
      "Epoch 218/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1603 - acc: 0.4868 - val_loss: 1.4949 - val_acc: 0.3808\n",
      "Epoch 219/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1624 - acc: 0.4905 - val_loss: 1.4878 - val_acc: 0.3771\n",
      "Epoch 220/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1549 - acc: 0.4902 - val_loss: 1.4962 - val_acc: 0.3715\n",
      "Epoch 221/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1530 - acc: 0.4891 - val_loss: 1.4971 - val_acc: 0.3685\n",
      "Epoch 222/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1540 - acc: 0.4961 - val_loss: 1.4903 - val_acc: 0.3735\n",
      "Epoch 223/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1660 - acc: 0.4913 - val_loss: 1.4856 - val_acc: 0.3741\n",
      "Epoch 224/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1678 - acc: 0.4816 - val_loss: 1.4855 - val_acc: 0.3755\n",
      "Epoch 225/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1525 - acc: 0.4892 - val_loss: 1.4891 - val_acc: 0.3745\n",
      "Epoch 226/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1656 - acc: 0.4878 - val_loss: 1.4882 - val_acc: 0.3751\n",
      "Epoch 227/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1632 - acc: 0.4876 - val_loss: 1.4990 - val_acc: 0.3741\n",
      "Epoch 228/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1583 - acc: 0.4910 - val_loss: 1.4893 - val_acc: 0.3738\n",
      "Epoch 229/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1556 - acc: 0.4902 - val_loss: 1.4936 - val_acc: 0.3678\n",
      "Epoch 230/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1570 - acc: 0.4907 - val_loss: 1.4934 - val_acc: 0.3718\n",
      "Epoch 231/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1617 - acc: 0.4873 - val_loss: 1.4902 - val_acc: 0.3745\n",
      "Epoch 232/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1638 - acc: 0.4886 - val_loss: 1.4927 - val_acc: 0.3705\n",
      "Epoch 233/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1589 - acc: 0.4855 - val_loss: 1.4947 - val_acc: 0.3735\n",
      "Epoch 234/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1587 - acc: 0.4914 - val_loss: 1.4957 - val_acc: 0.3758\n",
      "Epoch 235/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1582 - acc: 0.4866 - val_loss: 1.4885 - val_acc: 0.3768\n",
      "Epoch 236/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1572 - acc: 0.4927 - val_loss: 1.4901 - val_acc: 0.3705\n",
      "Epoch 237/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1624 - acc: 0.4883 - val_loss: 1.4974 - val_acc: 0.3668\n",
      "Epoch 238/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1602 - acc: 0.4887 - val_loss: 1.4943 - val_acc: 0.3708\n",
      "Epoch 239/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1582 - acc: 0.4867 - val_loss: 1.4884 - val_acc: 0.3748\n",
      "Epoch 240/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1600 - acc: 0.4919 - val_loss: 1.4937 - val_acc: 0.3688\n",
      "Epoch 241/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1613 - acc: 0.4872 - val_loss: 1.4958 - val_acc: 0.3705\n",
      "Epoch 242/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1627 - acc: 0.4881 - val_loss: 1.4915 - val_acc: 0.3701\n",
      "Epoch 243/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1590 - acc: 0.4927 - val_loss: 1.4945 - val_acc: 0.3711\n",
      "Epoch 244/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1577 - acc: 0.4867 - val_loss: 1.4927 - val_acc: 0.3711\n",
      "Epoch 245/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1553 - acc: 0.4886 - val_loss: 1.4889 - val_acc: 0.3715\n",
      "Epoch 246/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1574 - acc: 0.4900 - val_loss: 1.4981 - val_acc: 0.3751\n",
      "Epoch 247/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1607 - acc: 0.4951 - val_loss: 1.4918 - val_acc: 0.3771\n",
      "Epoch 248/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1650 - acc: 0.4896 - val_loss: 1.4909 - val_acc: 0.3741\n",
      "Epoch 249/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1554 - acc: 0.5008 - val_loss: 1.4945 - val_acc: 0.3741\n",
      "Epoch 250/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1644 - acc: 0.4903 - val_loss: 1.4908 - val_acc: 0.3751\n",
      "Epoch 251/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1594 - acc: 0.4966 - val_loss: 1.4836 - val_acc: 0.3721\n",
      "Epoch 252/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1552 - acc: 0.4917 - val_loss: 1.4906 - val_acc: 0.3748\n",
      "Epoch 253/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1635 - acc: 0.4852 - val_loss: 1.4851 - val_acc: 0.3785\n",
      "Epoch 254/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1679 - acc: 0.4857 - val_loss: 1.4905 - val_acc: 0.3651\n",
      "Epoch 255/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1655 - acc: 0.4882 - val_loss: 1.4903 - val_acc: 0.3688\n",
      "Epoch 256/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1549 - acc: 0.4912 - val_loss: 1.4975 - val_acc: 0.3738\n",
      "Epoch 257/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1478 - acc: 0.4929 - val_loss: 1.4990 - val_acc: 0.3758\n",
      "Epoch 258/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1610 - acc: 0.4863 - val_loss: 1.4953 - val_acc: 0.3741\n",
      "Epoch 259/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1677 - acc: 0.4868 - val_loss: 1.4928 - val_acc: 0.3701\n",
      "Epoch 260/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1593 - acc: 0.4892 - val_loss: 1.4897 - val_acc: 0.3691\n",
      "Epoch 261/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1571 - acc: 0.4952 - val_loss: 1.4924 - val_acc: 0.3698\n",
      "Epoch 262/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1558 - acc: 0.4920 - val_loss: 1.4961 - val_acc: 0.3661\n",
      "Epoch 263/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1539 - acc: 0.4939 - val_loss: 1.4975 - val_acc: 0.3748\n",
      "Epoch 264/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1582 - acc: 0.4922 - val_loss: 1.4909 - val_acc: 0.3735\n",
      "Epoch 265/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1584 - acc: 0.4905 - val_loss: 1.4873 - val_acc: 0.3738\n",
      "Epoch 266/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1587 - acc: 0.4912 - val_loss: 1.4976 - val_acc: 0.3685\n",
      "Epoch 267/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1562 - acc: 0.4922 - val_loss: 1.4911 - val_acc: 0.3718\n",
      "Epoch 268/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1585 - acc: 0.4927 - val_loss: 1.4985 - val_acc: 0.3745\n",
      "Epoch 269/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1615 - acc: 0.4848 - val_loss: 1.4917 - val_acc: 0.3741\n",
      "Epoch 270/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1559 - acc: 0.4913 - val_loss: 1.4930 - val_acc: 0.3758\n",
      "Epoch 271/500\n",
      "11994/11994 [==============================] - 0s 23us/step - loss: 1.1625 - acc: 0.4859 - val_loss: 1.4934 - val_acc: 0.3735\n",
      "Epoch 272/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1589 - acc: 0.4917 - val_loss: 1.4948 - val_acc: 0.3731\n",
      "Epoch 273/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1566 - acc: 0.4910 - val_loss: 1.4947 - val_acc: 0.3668\n",
      "Epoch 274/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1527 - acc: 0.4967 - val_loss: 1.4959 - val_acc: 0.3735\n",
      "Epoch 275/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1607 - acc: 0.4916 - val_loss: 1.4937 - val_acc: 0.3735\n",
      "Epoch 276/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1645 - acc: 0.4868 - val_loss: 1.4877 - val_acc: 0.3691\n",
      "Epoch 277/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1478 - acc: 0.4943 - val_loss: 1.4954 - val_acc: 0.3708\n",
      "Epoch 278/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1516 - acc: 0.4926 - val_loss: 1.4993 - val_acc: 0.3645\n",
      "Epoch 279/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1537 - acc: 0.4962 - val_loss: 1.5006 - val_acc: 0.3731\n",
      "Epoch 280/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1524 - acc: 0.4942 - val_loss: 1.4981 - val_acc: 0.3741\n",
      "Epoch 281/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1497 - acc: 0.4941 - val_loss: 1.4969 - val_acc: 0.3735\n",
      "Epoch 282/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1511 - acc: 0.4917 - val_loss: 1.4967 - val_acc: 0.3768\n",
      "Epoch 283/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1486 - acc: 0.5000 - val_loss: 1.4978 - val_acc: 0.3745\n",
      "Epoch 284/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1504 - acc: 0.4934 - val_loss: 1.4903 - val_acc: 0.3708\n",
      "Epoch 285/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1583 - acc: 0.4968 - val_loss: 1.5014 - val_acc: 0.3711\n",
      "Epoch 286/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1488 - acc: 0.4939 - val_loss: 1.4931 - val_acc: 0.3728\n",
      "Epoch 287/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1509 - acc: 0.4941 - val_loss: 1.4935 - val_acc: 0.3691\n",
      "Epoch 288/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1496 - acc: 0.4919 - val_loss: 1.4958 - val_acc: 0.3741\n",
      "Epoch 289/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1592 - acc: 0.4942 - val_loss: 1.4942 - val_acc: 0.3731\n",
      "Epoch 290/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1529 - acc: 0.4889 - val_loss: 1.4984 - val_acc: 0.3681\n",
      "Epoch 291/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1571 - acc: 0.4933 - val_loss: 1.4897 - val_acc: 0.3661\n",
      "Epoch 292/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1578 - acc: 0.4921 - val_loss: 1.4944 - val_acc: 0.3671\n",
      "Epoch 293/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1542 - acc: 0.4973 - val_loss: 1.4997 - val_acc: 0.3698\n",
      "Epoch 294/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1444 - acc: 0.4965 - val_loss: 1.5006 - val_acc: 0.3705\n",
      "Epoch 295/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1454 - acc: 0.4962 - val_loss: 1.4992 - val_acc: 0.3695\n",
      "Epoch 296/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1537 - acc: 0.4907 - val_loss: 1.5019 - val_acc: 0.3688\n",
      "Epoch 297/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1490 - acc: 0.4987 - val_loss: 1.5076 - val_acc: 0.3705\n",
      "Epoch 298/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1489 - acc: 0.5041 - val_loss: 1.5004 - val_acc: 0.3675\n",
      "Epoch 299/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1579 - acc: 0.4888 - val_loss: 1.4945 - val_acc: 0.3678\n",
      "Epoch 300/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1435 - acc: 0.4994 - val_loss: 1.4983 - val_acc: 0.3735\n",
      "Epoch 301/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1511 - acc: 0.4983 - val_loss: 1.4975 - val_acc: 0.3755\n",
      "Epoch 302/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1514 - acc: 0.5000 - val_loss: 1.4997 - val_acc: 0.3728\n",
      "Epoch 303/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1550 - acc: 0.4938 - val_loss: 1.4933 - val_acc: 0.3718\n",
      "Epoch 304/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1507 - acc: 0.4967 - val_loss: 1.4998 - val_acc: 0.3721\n",
      "Epoch 305/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1589 - acc: 0.4902 - val_loss: 1.4967 - val_acc: 0.3718\n",
      "Epoch 306/500\n",
      "11994/11994 [==============================] - 0s 18us/step - loss: 1.1562 - acc: 0.4912 - val_loss: 1.5021 - val_acc: 0.3635\n",
      "Epoch 307/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1536 - acc: 0.4922 - val_loss: 1.5001 - val_acc: 0.3691\n",
      "Epoch 308/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1488 - acc: 0.4970 - val_loss: 1.5026 - val_acc: 0.3671\n",
      "Epoch 309/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1487 - acc: 0.4972 - val_loss: 1.5066 - val_acc: 0.3655\n",
      "Epoch 310/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1542 - acc: 0.4951 - val_loss: 1.4915 - val_acc: 0.3695\n",
      "Epoch 311/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1478 - acc: 0.4921 - val_loss: 1.5008 - val_acc: 0.3671\n",
      "Epoch 312/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1512 - acc: 0.4932 - val_loss: 1.5035 - val_acc: 0.3705\n",
      "Epoch 313/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1565 - acc: 0.4950 - val_loss: 1.4908 - val_acc: 0.3718\n",
      "Epoch 314/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1542 - acc: 0.4979 - val_loss: 1.4946 - val_acc: 0.3688\n",
      "Epoch 315/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1548 - acc: 0.4927 - val_loss: 1.5004 - val_acc: 0.3678\n",
      "Epoch 316/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1562 - acc: 0.4969 - val_loss: 1.4994 - val_acc: 0.3721\n",
      "Epoch 317/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1526 - acc: 0.4945 - val_loss: 1.4957 - val_acc: 0.3731\n",
      "Epoch 318/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1540 - acc: 0.4977 - val_loss: 1.4953 - val_acc: 0.3711\n",
      "Epoch 319/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1490 - acc: 0.4975 - val_loss: 1.4930 - val_acc: 0.3715\n",
      "Epoch 320/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1458 - acc: 0.4949 - val_loss: 1.5026 - val_acc: 0.3728\n",
      "Epoch 321/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1445 - acc: 0.4976 - val_loss: 1.5044 - val_acc: 0.3698\n",
      "Epoch 322/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1520 - acc: 0.4934 - val_loss: 1.5059 - val_acc: 0.3705\n",
      "Epoch 323/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1579 - acc: 0.4911 - val_loss: 1.4982 - val_acc: 0.3685\n",
      "Epoch 324/500\n",
      "11994/11994 [==============================] - 0s 22us/step - loss: 1.1484 - acc: 0.4940 - val_loss: 1.5078 - val_acc: 0.3691\n",
      "Epoch 325/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1510 - acc: 0.4981 - val_loss: 1.5087 - val_acc: 0.3748\n",
      "Epoch 326/500\n",
      "11994/11994 [==============================] - 0s 24us/step - loss: 1.1511 - acc: 0.4975 - val_loss: 1.5016 - val_acc: 0.3695\n",
      "Epoch 327/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1537 - acc: 0.4953 - val_loss: 1.5053 - val_acc: 0.3685\n",
      "Epoch 328/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1471 - acc: 0.4908 - val_loss: 1.5071 - val_acc: 0.3725\n",
      "Epoch 329/500\n",
      "11994/11994 [==============================] - 0s 22us/step - loss: 1.1557 - acc: 0.4933 - val_loss: 1.5014 - val_acc: 0.3721\n",
      "Epoch 330/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1505 - acc: 0.4944 - val_loss: 1.5014 - val_acc: 0.3738\n",
      "Epoch 331/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1490 - acc: 0.4973 - val_loss: 1.4962 - val_acc: 0.3641\n",
      "Epoch 332/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1528 - acc: 0.4962 - val_loss: 1.4934 - val_acc: 0.3745\n",
      "Epoch 333/500\n",
      "11994/11994 [==============================] - 0s 22us/step - loss: 1.1584 - acc: 0.4894 - val_loss: 1.4928 - val_acc: 0.3721\n",
      "Epoch 334/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1514 - acc: 0.4962 - val_loss: 1.4968 - val_acc: 0.3768\n",
      "Epoch 335/500\n",
      "11994/11994 [==============================] - 0s 22us/step - loss: 1.1517 - acc: 0.4942 - val_loss: 1.4977 - val_acc: 0.3725\n",
      "Epoch 336/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1429 - acc: 0.5019 - val_loss: 1.5049 - val_acc: 0.3711\n",
      "Epoch 337/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1501 - acc: 0.4967 - val_loss: 1.5026 - val_acc: 0.3711\n",
      "Epoch 338/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1536 - acc: 0.4970 - val_loss: 1.4952 - val_acc: 0.3711\n",
      "Epoch 339/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1445 - acc: 0.5048 - val_loss: 1.4986 - val_acc: 0.3748\n",
      "Epoch 340/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1470 - acc: 0.5048 - val_loss: 1.5076 - val_acc: 0.3691\n",
      "Epoch 341/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1516 - acc: 0.4948 - val_loss: 1.5040 - val_acc: 0.3758\n",
      "Epoch 342/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1413 - acc: 0.4969 - val_loss: 1.5086 - val_acc: 0.3711\n",
      "Epoch 343/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1560 - acc: 0.4921 - val_loss: 1.4973 - val_acc: 0.3748\n",
      "Epoch 344/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1452 - acc: 0.4992 - val_loss: 1.5019 - val_acc: 0.3745\n",
      "Epoch 345/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1439 - acc: 0.4981 - val_loss: 1.5074 - val_acc: 0.3788\n",
      "Epoch 346/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1583 - acc: 0.4834 - val_loss: 1.5065 - val_acc: 0.3705\n",
      "Epoch 347/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1441 - acc: 0.5045 - val_loss: 1.5019 - val_acc: 0.3721\n",
      "Epoch 348/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1453 - acc: 0.4942 - val_loss: 1.5081 - val_acc: 0.3758\n",
      "Epoch 349/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1472 - acc: 0.4952 - val_loss: 1.5020 - val_acc: 0.3745\n",
      "Epoch 350/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1482 - acc: 0.4973 - val_loss: 1.5118 - val_acc: 0.3755\n",
      "Epoch 351/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1512 - acc: 0.4977 - val_loss: 1.5026 - val_acc: 0.3761\n",
      "Epoch 352/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1498 - acc: 0.4997 - val_loss: 1.4976 - val_acc: 0.3715\n",
      "Epoch 353/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1514 - acc: 0.4956 - val_loss: 1.5025 - val_acc: 0.3738\n",
      "Epoch 354/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1478 - acc: 0.4926 - val_loss: 1.5025 - val_acc: 0.3728\n",
      "Epoch 355/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1480 - acc: 0.4972 - val_loss: 1.5009 - val_acc: 0.3778\n",
      "Epoch 356/500\n",
      "11994/11994 [==============================] - 0s 18us/step - loss: 1.1457 - acc: 0.4996 - val_loss: 1.5021 - val_acc: 0.3705\n",
      "Epoch 357/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1493 - acc: 0.4977 - val_loss: 1.5007 - val_acc: 0.3741\n",
      "Epoch 358/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1445 - acc: 0.5003 - val_loss: 1.5041 - val_acc: 0.3738\n",
      "Epoch 359/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1487 - acc: 0.4966 - val_loss: 1.5066 - val_acc: 0.3708\n",
      "Epoch 360/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1536 - acc: 0.4951 - val_loss: 1.5006 - val_acc: 0.3665\n",
      "Epoch 361/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1524 - acc: 0.4977 - val_loss: 1.4986 - val_acc: 0.3791\n",
      "Epoch 362/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1518 - acc: 0.4988 - val_loss: 1.4996 - val_acc: 0.3688\n",
      "Epoch 363/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1459 - acc: 0.4959 - val_loss: 1.5046 - val_acc: 0.3711\n",
      "Epoch 364/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1527 - acc: 0.4936 - val_loss: 1.4971 - val_acc: 0.3748\n",
      "Epoch 365/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1471 - acc: 0.5003 - val_loss: 1.5042 - val_acc: 0.3755\n",
      "Epoch 366/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1499 - acc: 0.4972 - val_loss: 1.5050 - val_acc: 0.3681\n",
      "Epoch 367/500\n",
      "11994/11994 [==============================] - 0s 18us/step - loss: 1.1482 - acc: 0.4984 - val_loss: 1.5096 - val_acc: 0.3738\n",
      "Epoch 368/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1519 - acc: 0.4991 - val_loss: 1.5082 - val_acc: 0.3625\n",
      "Epoch 369/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1431 - acc: 0.4955 - val_loss: 1.5121 - val_acc: 0.3715\n",
      "Epoch 370/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1564 - acc: 0.4967 - val_loss: 1.5106 - val_acc: 0.3708\n",
      "Epoch 371/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1447 - acc: 0.4963 - val_loss: 1.5117 - val_acc: 0.3681\n",
      "Epoch 372/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1500 - acc: 0.4944 - val_loss: 1.5063 - val_acc: 0.3708\n",
      "Epoch 373/500\n",
      "11994/11994 [==============================] - 0s 22us/step - loss: 1.1462 - acc: 0.5019 - val_loss: 1.5116 - val_acc: 0.3731\n",
      "Epoch 374/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1449 - acc: 0.4962 - val_loss: 1.5076 - val_acc: 0.3708\n",
      "Epoch 375/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1390 - acc: 0.5008 - val_loss: 1.5153 - val_acc: 0.3721\n",
      "Epoch 376/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1445 - acc: 0.4988 - val_loss: 1.5117 - val_acc: 0.3665\n",
      "Epoch 377/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1524 - acc: 0.4950 - val_loss: 1.5137 - val_acc: 0.3675\n",
      "Epoch 378/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1506 - acc: 0.4972 - val_loss: 1.5109 - val_acc: 0.3691\n",
      "Epoch 379/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1489 - acc: 0.5012 - val_loss: 1.5028 - val_acc: 0.3711\n",
      "Epoch 380/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1426 - acc: 0.4947 - val_loss: 1.5098 - val_acc: 0.3648\n",
      "Epoch 381/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1467 - acc: 0.4937 - val_loss: 1.5063 - val_acc: 0.3688\n",
      "Epoch 382/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1365 - acc: 0.5043 - val_loss: 1.5157 - val_acc: 0.3741\n",
      "Epoch 383/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1471 - acc: 0.4961 - val_loss: 1.5059 - val_acc: 0.3675\n",
      "Epoch 384/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1374 - acc: 0.5026 - val_loss: 1.5033 - val_acc: 0.3778\n",
      "Epoch 385/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1413 - acc: 0.4970 - val_loss: 1.5019 - val_acc: 0.3675\n",
      "Epoch 386/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1509 - acc: 0.4931 - val_loss: 1.5066 - val_acc: 0.3681\n",
      "Epoch 387/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1483 - acc: 0.5012 - val_loss: 1.5070 - val_acc: 0.3651\n",
      "Epoch 388/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1458 - acc: 0.4982 - val_loss: 1.5040 - val_acc: 0.3681\n",
      "Epoch 389/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1452 - acc: 0.5005 - val_loss: 1.5088 - val_acc: 0.3745\n",
      "Epoch 390/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1402 - acc: 0.4986 - val_loss: 1.5103 - val_acc: 0.3748\n",
      "Epoch 391/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1439 - acc: 0.4998 - val_loss: 1.5057 - val_acc: 0.3738\n",
      "Epoch 392/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1440 - acc: 0.4969 - val_loss: 1.5056 - val_acc: 0.3721\n",
      "Epoch 393/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1445 - acc: 0.4999 - val_loss: 1.5084 - val_acc: 0.3688\n",
      "Epoch 394/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1566 - acc: 0.4978 - val_loss: 1.5047 - val_acc: 0.3691\n",
      "Epoch 395/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1464 - acc: 0.5031 - val_loss: 1.5033 - val_acc: 0.3658\n",
      "Epoch 396/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1410 - acc: 0.5035 - val_loss: 1.4987 - val_acc: 0.3765\n",
      "Epoch 397/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1476 - acc: 0.4928 - val_loss: 1.5046 - val_acc: 0.3731\n",
      "Epoch 398/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1467 - acc: 0.4962 - val_loss: 1.5007 - val_acc: 0.3695\n",
      "Epoch 399/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1472 - acc: 0.4988 - val_loss: 1.5022 - val_acc: 0.3705\n",
      "Epoch 400/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1431 - acc: 0.4992 - val_loss: 1.4986 - val_acc: 0.3708\n",
      "Epoch 401/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1429 - acc: 0.4998 - val_loss: 1.5078 - val_acc: 0.3745\n",
      "Epoch 402/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1515 - acc: 0.5024 - val_loss: 1.5004 - val_acc: 0.3725\n",
      "Epoch 403/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1459 - acc: 0.4965 - val_loss: 1.5062 - val_acc: 0.3731\n",
      "Epoch 404/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1426 - acc: 0.4990 - val_loss: 1.5054 - val_acc: 0.3708\n",
      "Epoch 405/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1366 - acc: 0.5030 - val_loss: 1.5120 - val_acc: 0.3671\n",
      "Epoch 406/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1347 - acc: 0.5042 - val_loss: 1.5081 - val_acc: 0.3675\n",
      "Epoch 407/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1474 - acc: 0.5000 - val_loss: 1.5076 - val_acc: 0.3721\n",
      "Epoch 408/500\n",
      "11994/11994 [==============================] - 0s 21us/step - loss: 1.1427 - acc: 0.4991 - val_loss: 1.5042 - val_acc: 0.3758\n",
      "Epoch 409/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1360 - acc: 0.5063 - val_loss: 1.5040 - val_acc: 0.3715\n",
      "Epoch 410/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1440 - acc: 0.4975 - val_loss: 1.4981 - val_acc: 0.3781\n",
      "Epoch 411/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1352 - acc: 0.5041 - val_loss: 1.5003 - val_acc: 0.3741\n",
      "Epoch 412/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1575 - acc: 0.4908 - val_loss: 1.5047 - val_acc: 0.3725\n",
      "Epoch 413/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1480 - acc: 0.4974 - val_loss: 1.4921 - val_acc: 0.3688\n",
      "Epoch 414/500\n",
      "11994/11994 [==============================] - 0s 18us/step - loss: 1.1439 - acc: 0.5003 - val_loss: 1.4995 - val_acc: 0.3745\n",
      "Epoch 415/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1407 - acc: 0.5003 - val_loss: 1.5023 - val_acc: 0.3748\n",
      "Epoch 416/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1450 - acc: 0.5024 - val_loss: 1.5031 - val_acc: 0.3721\n",
      "Epoch 417/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1473 - acc: 0.4965 - val_loss: 1.5072 - val_acc: 0.3708\n",
      "Epoch 418/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1443 - acc: 0.4987 - val_loss: 1.5037 - val_acc: 0.3725\n",
      "Epoch 419/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1489 - acc: 0.5006 - val_loss: 1.5030 - val_acc: 0.3688\n",
      "Epoch 420/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1444 - acc: 0.4985 - val_loss: 1.5048 - val_acc: 0.3701\n",
      "Epoch 421/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1465 - acc: 0.4987 - val_loss: 1.5027 - val_acc: 0.3708\n",
      "Epoch 422/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1474 - acc: 0.4973 - val_loss: 1.4974 - val_acc: 0.3701\n",
      "Epoch 423/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1459 - acc: 0.5000 - val_loss: 1.5097 - val_acc: 0.3735\n",
      "Epoch 424/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1404 - acc: 0.4996 - val_loss: 1.5038 - val_acc: 0.3761\n",
      "Epoch 425/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1436 - acc: 0.5028 - val_loss: 1.4967 - val_acc: 0.3738\n",
      "Epoch 426/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1402 - acc: 0.4993 - val_loss: 1.5021 - val_acc: 0.3718\n",
      "Epoch 427/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1395 - acc: 0.5024 - val_loss: 1.5066 - val_acc: 0.3731\n",
      "Epoch 428/500\n",
      "11994/11994 [==============================] - 0s 18us/step - loss: 1.1411 - acc: 0.4987 - val_loss: 1.5081 - val_acc: 0.3735\n",
      "Epoch 429/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1405 - acc: 0.5013 - val_loss: 1.5073 - val_acc: 0.3735\n",
      "Epoch 430/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1468 - acc: 0.4992 - val_loss: 1.5059 - val_acc: 0.3671\n",
      "Epoch 431/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1441 - acc: 0.5016 - val_loss: 1.4994 - val_acc: 0.3711\n",
      "Epoch 432/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1378 - acc: 0.5061 - val_loss: 1.5129 - val_acc: 0.3705\n",
      "Epoch 433/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1468 - acc: 0.4979 - val_loss: 1.5105 - val_acc: 0.3718\n",
      "Epoch 434/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1350 - acc: 0.5013 - val_loss: 1.5094 - val_acc: 0.3755\n",
      "Epoch 435/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1448 - acc: 0.4997 - val_loss: 1.5019 - val_acc: 0.3815\n",
      "Epoch 436/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1381 - acc: 0.4960 - val_loss: 1.5090 - val_acc: 0.3785\n",
      "Epoch 437/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1477 - acc: 0.4967 - val_loss: 1.5070 - val_acc: 0.3758\n",
      "Epoch 438/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1487 - acc: 0.4972 - val_loss: 1.4923 - val_acc: 0.3741\n",
      "Epoch 439/500\n",
      "11994/11994 [==============================] - 0s 20us/step - loss: 1.1396 - acc: 0.5044 - val_loss: 1.5087 - val_acc: 0.3815\n",
      "Epoch 440/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1416 - acc: 0.4989 - val_loss: 1.5091 - val_acc: 0.3745\n",
      "Epoch 441/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1332 - acc: 0.5032 - val_loss: 1.5128 - val_acc: 0.3695\n",
      "Epoch 442/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1283 - acc: 0.5047 - val_loss: 1.5164 - val_acc: 0.3725\n",
      "Epoch 443/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1422 - acc: 0.5000 - val_loss: 1.5067 - val_acc: 0.3771\n",
      "Epoch 444/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1423 - acc: 0.5043 - val_loss: 1.5091 - val_acc: 0.3738\n",
      "Epoch 445/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1389 - acc: 0.5014 - val_loss: 1.5019 - val_acc: 0.3775\n",
      "Epoch 446/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1457 - acc: 0.4988 - val_loss: 1.5039 - val_acc: 0.3705\n",
      "Epoch 447/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1440 - acc: 0.4975 - val_loss: 1.5097 - val_acc: 0.3725\n",
      "Epoch 448/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1411 - acc: 0.5011 - val_loss: 1.5089 - val_acc: 0.3751\n",
      "Epoch 449/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1460 - acc: 0.5000 - val_loss: 1.5018 - val_acc: 0.3775\n",
      "Epoch 450/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1362 - acc: 0.5037 - val_loss: 1.5084 - val_acc: 0.3735\n",
      "Epoch 451/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1487 - acc: 0.4964 - val_loss: 1.5111 - val_acc: 0.3715\n",
      "Epoch 452/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1500 - acc: 0.4987 - val_loss: 1.5062 - val_acc: 0.3735\n",
      "Epoch 453/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1454 - acc: 0.4948 - val_loss: 1.5071 - val_acc: 0.3691\n",
      "Epoch 454/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1441 - acc: 0.5050 - val_loss: 1.5069 - val_acc: 0.3785\n",
      "Epoch 455/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1470 - acc: 0.4997 - val_loss: 1.5052 - val_acc: 0.3735\n",
      "Epoch 456/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1388 - acc: 0.5068 - val_loss: 1.5070 - val_acc: 0.3715\n",
      "Epoch 457/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1365 - acc: 0.5068 - val_loss: 1.5041 - val_acc: 0.3741\n",
      "Epoch 458/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1369 - acc: 0.5038 - val_loss: 1.5163 - val_acc: 0.3731\n",
      "Epoch 459/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1376 - acc: 0.5015 - val_loss: 1.5082 - val_acc: 0.3758\n",
      "Epoch 460/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1357 - acc: 0.5044 - val_loss: 1.5093 - val_acc: 0.3715\n",
      "Epoch 461/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1449 - acc: 0.4998 - val_loss: 1.5084 - val_acc: 0.3748\n",
      "Epoch 462/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1471 - acc: 0.4937 - val_loss: 1.4974 - val_acc: 0.3781\n",
      "Epoch 463/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1331 - acc: 0.5034 - val_loss: 1.5105 - val_acc: 0.3698\n",
      "Epoch 464/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1416 - acc: 0.4967 - val_loss: 1.5066 - val_acc: 0.3731\n",
      "Epoch 465/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1395 - acc: 0.4963 - val_loss: 1.5105 - val_acc: 0.3755\n",
      "Epoch 466/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1423 - acc: 0.4997 - val_loss: 1.5157 - val_acc: 0.3775\n",
      "Epoch 467/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1402 - acc: 0.5021 - val_loss: 1.5113 - val_acc: 0.3755\n",
      "Epoch 468/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1495 - acc: 0.4985 - val_loss: 1.5131 - val_acc: 0.3771\n",
      "Epoch 469/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1373 - acc: 0.5038 - val_loss: 1.5129 - val_acc: 0.3708\n",
      "Epoch 470/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1306 - acc: 0.5043 - val_loss: 1.5195 - val_acc: 0.3675\n",
      "Epoch 471/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1400 - acc: 0.4994 - val_loss: 1.5147 - val_acc: 0.3715\n",
      "Epoch 472/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1348 - acc: 0.5051 - val_loss: 1.5217 - val_acc: 0.3781\n",
      "Epoch 473/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1413 - acc: 0.5006 - val_loss: 1.5137 - val_acc: 0.3745\n",
      "Epoch 474/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1418 - acc: 0.5045 - val_loss: 1.5100 - val_acc: 0.3701\n",
      "Epoch 475/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1463 - acc: 0.4980 - val_loss: 1.5029 - val_acc: 0.3735\n",
      "Epoch 476/500\n",
      "11994/11994 [==============================] - 0s 18us/step - loss: 1.1350 - acc: 0.5036 - val_loss: 1.5124 - val_acc: 0.3705\n",
      "Epoch 477/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1402 - acc: 0.5066 - val_loss: 1.5124 - val_acc: 0.3718\n",
      "Epoch 478/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1507 - acc: 0.4973 - val_loss: 1.5061 - val_acc: 0.3731\n",
      "Epoch 479/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1418 - acc: 0.4947 - val_loss: 1.5111 - val_acc: 0.3715\n",
      "Epoch 480/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1357 - acc: 0.5082 - val_loss: 1.5120 - val_acc: 0.3685\n",
      "Epoch 481/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1398 - acc: 0.4987 - val_loss: 1.5109 - val_acc: 0.3615\n",
      "Epoch 482/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1401 - acc: 0.5015 - val_loss: 1.5124 - val_acc: 0.3661\n",
      "Epoch 483/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1494 - acc: 0.5011 - val_loss: 1.5060 - val_acc: 0.3681\n",
      "Epoch 484/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1406 - acc: 0.5048 - val_loss: 1.5070 - val_acc: 0.3718\n",
      "Epoch 485/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1377 - acc: 0.5029 - val_loss: 1.5138 - val_acc: 0.3738\n",
      "Epoch 486/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1404 - acc: 0.5032 - val_loss: 1.5156 - val_acc: 0.3711\n",
      "Epoch 487/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1412 - acc: 0.5009 - val_loss: 1.5086 - val_acc: 0.3695\n",
      "Epoch 488/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1367 - acc: 0.5050 - val_loss: 1.5130 - val_acc: 0.3698\n",
      "Epoch 489/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1429 - acc: 0.4957 - val_loss: 1.5137 - val_acc: 0.3671\n",
      "Epoch 490/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1326 - acc: 0.5065 - val_loss: 1.5127 - val_acc: 0.3635\n",
      "Epoch 491/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1428 - acc: 0.5011 - val_loss: 1.5120 - val_acc: 0.3675\n",
      "Epoch 492/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1430 - acc: 0.5052 - val_loss: 1.5117 - val_acc: 0.3755\n",
      "Epoch 493/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1351 - acc: 0.5063 - val_loss: 1.5100 - val_acc: 0.3711\n",
      "Epoch 494/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1345 - acc: 0.5049 - val_loss: 1.5184 - val_acc: 0.3778\n",
      "Epoch 495/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1458 - acc: 0.5038 - val_loss: 1.5047 - val_acc: 0.3685\n",
      "Epoch 496/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1391 - acc: 0.5052 - val_loss: 1.5102 - val_acc: 0.3728\n",
      "Epoch 497/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1409 - acc: 0.5019 - val_loss: 1.5078 - val_acc: 0.3718\n",
      "Epoch 498/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1343 - acc: 0.5009 - val_loss: 1.5185 - val_acc: 0.3691\n",
      "Epoch 499/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1347 - acc: 0.5043 - val_loss: 1.5158 - val_acc: 0.3741\n",
      "Epoch 500/500\n",
      "11994/11994 [==============================] - 0s 19us/step - loss: 1.1351 - acc: 0.5016 - val_loss: 1.5101 - val_acc: 0.3728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14b62ed30>"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    csv_dataset, one_hot_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# class_weights = compute_class_weight('balanced',np.unique(labels),labels)\n",
    "# sample_weights = np.array([class_weights[index[0,0]] for index in np.argmax(y_train,axis = 1)])\n",
    "model.fit(X_train, y_train, validation_data = (X_test,y_test), epochs=500, batch_size= 256)\n",
    "#model.fit(X_train, y_train, validation_data = (X_test,y_test), epochs=50, batch_size= 256, sample_weight=sample_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
