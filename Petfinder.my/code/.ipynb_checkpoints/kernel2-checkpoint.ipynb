{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'test_sentiment', 'train_sentiment', 'train']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "working_dir = \"../input\"\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import ttest_ind_from_stats\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.preprocessing import  OneHotEncoder\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import xgboost as xgb\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def load_csv(path):\n",
    "    csv_dataset = pd.read_csv(path,index_col=\"PetID\")\n",
    "    return csv_dataset\n",
    "\n",
    "def map_name(name):\n",
    "    name = str(name).lower()\n",
    "    count = 0\n",
    "    if name.find(\"name\") >=0 or name.find(\"noname\") >=0 or name.find(\"nameless\") >=0 or name.find(\"no name\") >=0 or name.find(\"unname\") >=0 or name.find(\"to be name\") >=0 or name.find(\"found\") >= 0 or name.find(\"yet\") >=0 or name.find(\"name less\") >=0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "def transfor_features(csv_dataset):\n",
    "    csv_dataset[\"Name\"] = csv_dataset[\"Name\"] .apply(map_name)\n",
    "    csv_dataset.drop([\"RescuerID\",\"Description\"],axis = 1, inplace=True)\n",
    "    return csv_dataset\n",
    "\n",
    "def get_max_abslute(sentences):\n",
    "    max_ = 0\n",
    "    real = 0\n",
    "    for sentence in sentences:\n",
    "        tmp = abs(sentence['sentiment']['score'])\n",
    "        if tmp > max_:\n",
    "            max_ = tmp\n",
    "            real = sentence['sentiment']['score'] * sentence['sentiment']['magnitude']\n",
    "    return real\n",
    "\n",
    "def get_sentiment_dict(path):\n",
    "    score_dict = {}\n",
    "    score_magnitude = {}\n",
    "    max_score = {}\n",
    "    \n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".json\"):\n",
    "            PetID = file.split(\".\")[0]\n",
    "            with open(path + file,\"r\") as f:\n",
    "                content = json.loads(f.read())\n",
    "\n",
    "            max_score[PetID] = get_max_abslute(content['sentences'])\n",
    "            score_magnitude[PetID] = content['documentSentiment']['score'] * content['documentSentiment']['magnitude']\n",
    "            score_dict[PetID] = content['documentSentiment']['score']\n",
    "    return score_dict,score_magnitude,max_score\n",
    "\n",
    "\n",
    "def change_breed_train(csv_dataset):\n",
    "    breed1_dict = {}\n",
    "    all_breed1 = csv_dataset[\"Breed1\"].unique().tolist()\n",
    "    for name,group in csv_dataset.groupby(\"Breed1\"):\n",
    "        tmp_sum = 0\n",
    "        for index, value in group.groupby(\"AdoptionSpeed\").size().iteritems():\n",
    "            tmp_sum += index * value / group.shape[0] \n",
    "        breed1_dict[name] = tmp_sum\n",
    "\n",
    "    csv_dataset[\"Breed1\"] = csv_dataset[\"Breed1\"].replace(breed1_dict)\n",
    "\n",
    "\n",
    "    breed2_dict = {}\n",
    "    all_breed2 = csv_dataset[\"Breed2\"].unique().tolist()\n",
    "    for name,group in csv_dataset.groupby(\"Breed2\"):\n",
    "        tmp_sum = 0\n",
    "        for index, value in group.groupby(\"AdoptionSpeed\").size().iteritems():\n",
    "            tmp_sum += index * value / group.shape[0] \n",
    "        breed2_dict[name] = tmp_sum\n",
    "\n",
    "\n",
    "    csv_dataset[\"Breed2\"] = csv_dataset[\"Breed2\"].replace(breed2_dict)\n",
    "    return breed1_dict,breed2_dict\n",
    "\n",
    "\n",
    "\n",
    "def change_breed_test(csv_dataset,breed1_dict,breed2_dict):\n",
    "    \n",
    "    csv_dataset[\"Breed1\"] = csv_dataset[\"Breed1\"].replace(breed1_dict)\n",
    "    csv_dataset[\"Breed2\"] = csv_dataset[\"Breed2\"].replace(breed2_dict)\n",
    "    \n",
    "\n",
    "def add_nlp_features(all_features,path):    \n",
    "    score_dict,score_magnitude,max_score = get_sentiment_dict(path)\n",
    "    all_features[\"score_magnitude\"] = all_features.index\n",
    "    all_features[\"score_magnitude\"] = all_features[\"score_magnitude\"].replace(score_magnitude)\n",
    "\n",
    "    all_features[\"score\"] = all_features.index\n",
    "    all_features[\"score\"] = all_features[\"score\"].replace(score_dict)\n",
    "\n",
    "    all_features[\"max_score\"] = all_features.index\n",
    "    all_features[\"max_score\"] = all_features[\"max_score\"].replace(max_score)\n",
    "    \n",
    "    \n",
    "    def func(value):\n",
    "        if type(value) == type(\"value\"):\n",
    "            return 0\n",
    "        else:\n",
    "            return value\n",
    "    \n",
    "    all_features[\"score_magnitude\"] = all_features[\"score_magnitude\"].apply(func)\n",
    "    all_features[\"score\"] = all_features[\"score\"].apply(func)\n",
    "    all_features[\"max_score\"] = all_features[\"max_score\"].apply(func)\n",
    "    \n",
    "    return all_features\n",
    "\n",
    "\n",
    "def standard_and_dummy(all_features):\n",
    "    ## 标准化数字特征\n",
    "    numerical_features = [\"Age\",\"Breed1\",\"Breed2\",\"VideoAmt\",\"PhotoAmt\",\"Fee\",\"Quantity\",\"score_magnitude\",\"score\",\"max_score\"]\n",
    "    non_numerical_features = [feature for feature in all_features.columns if feature not in numerical_features]\n",
    "\n",
    "    all_features[numerical_features] = all_features[numerical_features].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))\n",
    "    all_features = all_features.fillna(all_features.mean())\n",
    "    \n",
    "    ## 离散化类别特征\n",
    "    all_features = pd.get_dummies(all_features, dummy_na=False, columns = non_numerical_features)\n",
    "    return all_features\n",
    "\n",
    "def prapare_dataset(train_path, test_path, train_nlp_path, test_nlp_path):\n",
    "    train_dataset = load_csv(train_path)\n",
    "    train_dataset[\"Name\"].fillna(value = \"noname\", inplace = True)\n",
    "    train_dataset = transfor_features(train_dataset)   \n",
    "    \n",
    "    ## 修改 breed 特征\n",
    "    breed1_dict,breed2_dict = change_breed_train(train_dataset)\n",
    "    \n",
    "    \n",
    "    test_dataset = load_csv(test_path)\n",
    "    test_dataset[\"Name\"].fillna(value = \"noname\", inplace = True)\n",
    "    test_dataset = transfor_features(test_dataset)\n",
    "    \n",
    "    ## 修改 breed 特征\n",
    "    change_breed_test(test_dataset,breed1_dict,breed2_dict)\n",
    "    \n",
    "\n",
    "    labels = train_dataset.iloc[:,-1]\n",
    "    train_dataset = train_dataset.iloc[:,0:-1]\n",
    "    \n",
    "    train_features = add_nlp_features(train_dataset,train_nlp_path)\n",
    "    test_features = add_nlp_features(test_dataset,test_nlp_path)\n",
    "\n",
    "    all_features = pd.concat([train_features,test_features])\n",
    "    all_features = standard_and_dummy(all_features)\n",
    "\n",
    "    return all_features.loc[train_features.index.tolist(),:],all_features.loc[test_features.index.tolist(),:],labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "_uuid": "065821d1349570e5cc42f5339877a5b7bd9b486b"
   },
   "outputs": [],
   "source": [
    "train_path = working_dir+\"/train\"+\"/train.csv\"\n",
    "train_nlp_path = working_dir + \"/train_sentiment/\"\n",
    "test_path = working_dir + \"/test\" + \"/test.csv\"\n",
    "test_nlp_path = working_dir + \"/test_sentiment/\"\n",
    "\n",
    "train_features, test_features, labels = prapare_dataset(train_path, test_path, train_nlp_path, test_nlp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "_uuid": "426d38bea19da57dd5a4d3f603323ddc5bda7a3b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Fee</th>\n",
       "      <th>VideoAmt</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>score_magnitude</th>\n",
       "      <th>score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>...</th>\n",
       "      <th>State_41330</th>\n",
       "      <th>State_41332</th>\n",
       "      <th>State_41335</th>\n",
       "      <th>State_41336</th>\n",
       "      <th>State_41342</th>\n",
       "      <th>State_41345</th>\n",
       "      <th>State_41361</th>\n",
       "      <th>State_41367</th>\n",
       "      <th>State_41401</th>\n",
       "      <th>State_41415</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PetID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86e1089a3</th>\n",
       "      <td>-0.421093</td>\n",
       "      <td>-0.045175</td>\n",
       "      <td>-0.024371</td>\n",
       "      <td>-0.390451</td>\n",
       "      <td>0.960741</td>\n",
       "      <td>-0.162955</td>\n",
       "      <td>-0.816653</td>\n",
       "      <td>0.163569</td>\n",
       "      <td>0.099727</td>\n",
       "      <td>0.418541</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6296e909a</th>\n",
       "      <td>-0.530696</td>\n",
       "      <td>-0.066649</td>\n",
       "      <td>-0.024371</td>\n",
       "      <td>-0.390451</td>\n",
       "      <td>-0.279382</td>\n",
       "      <td>-0.162955</td>\n",
       "      <td>-0.532363</td>\n",
       "      <td>-0.984042</td>\n",
       "      <td>-1.700960</td>\n",
       "      <td>-1.971336</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422e4906</th>\n",
       "      <td>-0.530696</td>\n",
       "      <td>0.040329</td>\n",
       "      <td>-0.024371</td>\n",
       "      <td>-0.390451</td>\n",
       "      <td>-0.279382</td>\n",
       "      <td>-0.162955</td>\n",
       "      <td>0.889087</td>\n",
       "      <td>0.190258</td>\n",
       "      <td>-0.260411</td>\n",
       "      <td>-3.046781</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5842f1ff5</th>\n",
       "      <td>-0.366291</td>\n",
       "      <td>0.040329</td>\n",
       "      <td>-0.024371</td>\n",
       "      <td>-0.390451</td>\n",
       "      <td>1.580803</td>\n",
       "      <td>-0.162955</td>\n",
       "      <td>1.173377</td>\n",
       "      <td>0.283668</td>\n",
       "      <td>2.260550</td>\n",
       "      <td>0.824820</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850a43f90</th>\n",
       "      <td>-0.530696</td>\n",
       "      <td>0.040329</td>\n",
       "      <td>-0.024371</td>\n",
       "      <td>-0.390451</td>\n",
       "      <td>-0.279382</td>\n",
       "      <td>-0.162955</td>\n",
       "      <td>-0.248073</td>\n",
       "      <td>2.165217</td>\n",
       "      <td>1.180138</td>\n",
       "      <td>0.418541</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age    Breed1    Breed2  Quantity       Fee  VideoAmt  \\\n",
       "PetID                                                                   \n",
       "86e1089a3 -0.421093 -0.045175 -0.024371 -0.390451  0.960741 -0.162955   \n",
       "6296e909a -0.530696 -0.066649 -0.024371 -0.390451 -0.279382 -0.162955   \n",
       "3422e4906 -0.530696  0.040329 -0.024371 -0.390451 -0.279382 -0.162955   \n",
       "5842f1ff5 -0.366291  0.040329 -0.024371 -0.390451  1.580803 -0.162955   \n",
       "850a43f90 -0.530696  0.040329 -0.024371 -0.390451 -0.279382 -0.162955   \n",
       "\n",
       "           PhotoAmt  score_magnitude     score  max_score  ...  State_41330  \\\n",
       "PetID                                                      ...                \n",
       "86e1089a3 -0.816653         0.163569  0.099727   0.418541  ...            0   \n",
       "6296e909a -0.532363        -0.984042 -1.700960  -1.971336  ...            0   \n",
       "3422e4906  0.889087         0.190258 -0.260411  -3.046781  ...            0   \n",
       "5842f1ff5  1.173377         0.283668  2.260550   0.824820  ...            0   \n",
       "850a43f90 -0.248073         2.165217  1.180138   0.418541  ...            0   \n",
       "\n",
       "           State_41332  State_41335  State_41336  State_41342  State_41345  \\\n",
       "PetID                                                                        \n",
       "86e1089a3            0            0            0            0            0   \n",
       "6296e909a            0            0            0            0            0   \n",
       "3422e4906            0            0            0            0            0   \n",
       "5842f1ff5            0            0            0            0            0   \n",
       "850a43f90            0            0            0            0            0   \n",
       "\n",
       "           State_41361  State_41367  State_41401  State_41415  \n",
       "PetID                                                          \n",
       "86e1089a3            0            0            0            0  \n",
       "6296e909a            0            0            1            0  \n",
       "3422e4906            0            0            0            0  \n",
       "5842f1ff5            0            0            1            0  \n",
       "850a43f90            0            0            0            0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "_uuid": "14e7c9c758888bf5fa896e2ac64067f61af2b997"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14993, 70), (3948, 70), (14993,))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape, test_features.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "_uuid": "de23c6dba7eaaf65260bb53197466ad8f727fbe3"
   },
   "outputs": [],
   "source": [
    "# def tune_parameters(training_dataset,labels):\n",
    "    \n",
    "#     tuned_parameters = {\n",
    "#     \"estimator__solver\": [\"lbfgs\",\"sag\"],\n",
    "#     \"estimator__C\": [0.1, 1,10],\n",
    "#     \"estimator__max_iter\": [500,1000],\n",
    "#     \"estimator__fit_intercept\": [True,False],\n",
    "#     }\n",
    "\n",
    "#     scores = ['accuracy']\n",
    "\n",
    "#     # 将数据集分成训练集和测试集\n",
    "                        \n",
    "#     for score in scores:\n",
    "#         print(\"# Tuning hyper-parameters for %s\\n\" % score)\n",
    "\n",
    "#         clf = GridSearchCV(OneVsRestClassifier(LogisticRegression()), tuned_parameters, cv = 5,\n",
    "#                            scoring='%s' % score)\n",
    "\n",
    "#         clf.fit(training_dataset, labels)\n",
    "\n",
    "#         print(\"Best parameters set found on development set:\\n\")\n",
    "#         #输出最优的模型参数\n",
    "#         print(clf.best_params_)\n",
    "        \n",
    "#     return clf\n",
    "\n",
    "# model = tune_parameters(train_features,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "_uuid": "6371b89ffac4d41ce34928f59c44399334ccb425"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_features, labels, test_size=0.2, random_state=0)\n",
    "\n",
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'multi:softmax',  # 多分类的问题\n",
    "    'num_class': 5,               # 类别数，与 multisoftmax 并用\n",
    "    'gamma': 0.1,                  # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。\n",
    "    'max_depth': 6,               # 构建树的深度，越大越容易过拟合\n",
    "    'lambda': 2,                   # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "    'subsample': 0.8,              # 随机采样训练样本\n",
    "    'colsample_bytree': 0.8,       # 生成树时进行的列采样\n",
    "    'min_child_weight': 3,\n",
    "    'silent': 1,                   # 设置成1则没有运行信息输出，最好是设置为0.\n",
    "    'eta': 0.01,                 \n",
    "    'seed': 1000,\n",
    "    'nthread': 4,                  # cpu 线程数\n",
    "}\n",
    "\n",
    "clf = xgb.XGBModel(**params)\n",
    "model = clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42880960320106704\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.07      0.83      0.12         6\n",
      "         1.0       0.37      0.41      0.39       581\n",
      "         2.0       0.40      0.35      0.38       915\n",
      "         3.0       0.26      0.41      0.32       414\n",
      "         4.0       0.67      0.51      0.58      1083\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      2999\n",
      "   macro avg       0.35      0.50      0.36      2999\n",
      "weighted avg       0.47      0.43      0.44      2999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "print(sum(pred == y_test)/len(pred))\n",
    "print(classification_report(pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "_uuid": "30bf0d0199c2ffdb4a8b08880962114bd27cca97"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PetID</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>378fcc4fc</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73c10e136</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72000c4c5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e147a4b9f</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43fbba852</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>77a490ec9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28c4b1b13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>d1eada628</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>d134dec34</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bcd464bb8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PetID  AdoptionSpeed\n",
       "0  378fcc4fc              2\n",
       "1  73c10e136              4\n",
       "2  72000c4c5              4\n",
       "3  e147a4b9f              2\n",
       "4  43fbba852              4\n",
       "5  77a490ec9              4\n",
       "6  28c4b1b13              4\n",
       "7  d1eada628              4\n",
       "8  d134dec34              4\n",
       "9  bcd464bb8              1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels = model.predict(test_features)\n",
    "output = pd.DataFrame(\n",
    "    data = { \"PetID\": test_features.index,\n",
    "            \"AdoptionSpeed\": pred_labels  \n",
    "            },\n",
    "    dtype = np.int32\n",
    ")\n",
    "output.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "56191fb618df1c69945018f7a1639b19346cdafd"
   },
   "outputs": [],
   "source": [
    "output.to_csv(\"submission.csv\",index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
